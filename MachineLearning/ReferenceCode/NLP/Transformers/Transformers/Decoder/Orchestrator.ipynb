{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitanya Belwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "from Decoder import Decoder\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Decoder and tensor size with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y Shape: torch.Size([8, 512, 20000])\n"
     ]
    }
   ],
   "source": [
    "model = Decoder(20_000, 1024, 16, 64, 4, 2, 0.1)\n",
    "\n",
    "# 20,000 is the vocab size\n",
    "x = np.random.randint(0, 20_000, size=(8, 512)) # 20_000 is meant  for easeir reading\n",
    "x_t = torch.tensor(x)\n",
    "\n",
    "# Pass the x through the model\n",
    "y_t = model(x_t) # _t is for tensor\n",
    "print(\"y Shape:\", y_t.shape)\n",
    "\n",
    "# Shape is (8, 512, 20_000) which is the batch size, sequence length, and vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitanya Belwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For tokenization of data\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# we'll use the same dataset, just ignore the labels\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "  return tokenizer(batch['sentence'], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    [\"sentence\", \"idx\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=1,  #32, # number of samples per batch\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: input_ids v: tensor([[  101,  7678, 22556,  1106,  1103,  6976,  5945,  1105, 27668,   102]])\n",
      "k: input_ids v.shape: torch.Size([1, 10])\n",
      "k: attention_mask v: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "k: attention_mask v.shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# check how it works\n",
    "# k has [input_ids, attention_mask] and v has the values\n",
    "for batch in train_loader:\n",
    "  for k, v in batch.items():\n",
    "    print(\"k:\", k, \"v:\", v)\n",
    "    print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "model = Decoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_len=tokenizer.max_len_single_sentence, #max_model_input_sizes[checkpoint],\n",
    "    d_k=16,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=28996, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"CUDA:\",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# A function to encapsulate the training loop\n",
    "# N - batch size \n",
    "# T - sequence length (number of tokens in a sentence)\n",
    "# V - vocab size\n",
    "def train(model, criterion, optimizer, train_loader, epochs):\n",
    "  train_losses = np.zeros(epochs)\n",
    "\n",
    "  for it in range(epochs):\n",
    "    model.train()\n",
    "    t0 = datetime.now()\n",
    "    train_loss = []\n",
    "    for batch in train_loader:\n",
    "      # move data to GPU\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # shift targets backwards\n",
    "      # Original: <CLS> The cat sat on the mat <SEP>\n",
    "      # Becomes: The cat sat on the mat <SEP> <PAD>\n",
    "      targets = batch['input_ids'].clone().detach()\n",
    "      targets = torch.roll(targets, shifts=-1, dims=1)\n",
    "      # PAD token is ignored in the loss so set last token to PAD\n",
    "      targets[:, -1] = tokenizer.pad_token_id\n",
    "\n",
    "      # Print the inputs -----------\n",
    "      #print(batch['input_ids'].shape,batch['input_ids'])\n",
    "      #print(tokenizer.decode(batch['input_ids'][0]))\n",
    "      #  -----------\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "      # outputs are N x T x V\n",
    "      # but PyTorch expects N x V x T\n",
    "      # print(\"outputs:\", outputs)\n",
    "      # print(\"targets:\", targets)\n",
    "      loss = criterion(outputs.transpose(2, 1), targets)\n",
    "      # N, T, V = outputs.shape\n",
    "      # loss = criterion(outputs.view(N * T, V), targets.view(N * T))\n",
    "        \n",
    "      # Backward and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss.append(loss.item())\n",
    "\n",
    "    # Get train loss and test loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    # Save losses\n",
    "    train_losses[it] = train_loss\n",
    "    \n",
    "    dt = datetime.now() - t0\n",
    "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Duration: {dt}')\n",
    "  \n",
    "  return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Optim and criterion\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9]) tensor([[  101,  1451,  2046, 11778,  1116,  1103,  6548,  3853,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] every shot enhances the excellent performances [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101,  5049, 22857,   102]], device='cuda:0')\n",
      "[CLS] operates nicely [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 2296, 1176,  170, 1632, 4007, 3767,  102]], device='cuda:0')\n",
      "[CLS] feeling like a great missed opportunity [SEP]\n",
      "torch.Size([1, 13]) tensor([[ 101, 1110, 1376, 1167, 1190,  170, 8796, 2523, 2011, 1106, 2311, 1159,\n",
      "          102]], device='cuda:0')\n",
      "[CLS] is little more than a mall movie designed to kill time [SEP]\n",
      "torch.Size([1, 17]) tensor([[ 101, 1142, 1110,  170, 1843,  117,  176, 7729, 2340,  117, 2121, 6276,\n",
      "         1376,  176, 5521,  119,  102]], device='cuda:0')\n",
      "[CLS] this is a dark, gritty, sometimes funny little gem. [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,   178, 11604, 22398, 15298,  8362,  7804,  3382,  1821,  9725,\n",
      "          3633,   102]], device='cuda:0')\n",
      "[CLS] irresistibly uncanny ambience [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,   171, 23225,  1183,  2523,   102]], device='cuda:0')\n",
      "[CLS] blustery movie [SEP]\n",
      "torch.Size([1, 32]) tensor([[ 101, 1122, 1110, 1145, 8208, 1118, 1122,  118,  118, 1103, 1912, 1104,\n",
      "         2523, 1115, 1128, 5548, 1167, 1272, 1128,  112, 1231, 1141, 1104, 1103,\n",
      "         6918, 1374, 1150, 4110, 1122, 1149,  119,  102]], device='cuda:0')\n",
      "[CLS] it is also elevated by it - - the kind of movie that you enjoy more because you're one of the lucky few who sought it out. [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1207, 1912,  102]], device='cuda:0')\n",
      "[CLS] new kind [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  1141, 14449,  1193, 10126,   118,  1702,  4728,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] one spectacularly ugly - looking broad [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101,  117, 1122, 3370, 1106, 1128,  119,  102]], device='cuda:0')\n",
      "[CLS], it gets to you. [SEP]\n",
      "torch.Size([1, 24]) tensor([[ 101, 1175, 1132, 1199, 5558, 1115, 1855, 1128, 1121, 1103, 1148, 2741,\n",
      "         1105, 1128, 1221, 1122,  112,  188, 1280, 1106, 1129,  170, 3868,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] there are some movies that hit you from the first scene and you know it's going to be a trip [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101,  1144,  1167,  1190,   170,  1374,  4899,  1115,  1132, 14222,\n",
      "          2365,  1536,  1106,  1129, 15263,  1193,  3801,  1107,  1103, 12401,\n",
      "          1193, 10467, 20214,  1104,  2523, 25251,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] has more than a few moments that are insightful enough to be fondly remembered in the endlessly challenging maze of moviegoing. [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1618, 6890,  102]], device='cuda:0')\n",
      "[CLS] better elsewhere [SEP]\n",
      "torch.Size([1, 30]) tensor([[  101,  1106,  1129,  9470,  1154,  1103,  1297,  1104,   192, 23850,\n",
      "          6834,  9598,   188,  1584,  8508, 12151,   117,  1150,  1110,  1136,\n",
      "          1178,   170,  9003,   117,  1133,   170,  1363,  1769,  1217,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] to be transported into the life of wladyslaw szpilman, who is not only a pianist, but a good human being [SEP]\n",
      "torch.Size([1, 3]) tensor([[  101, 27101,   102]], device='cuda:0')\n",
      "[CLS] gangster [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101, 24017,  1105,   172, 26179,  1158,   102]], device='cuda:0')\n",
      "[CLS] predictable and cloying [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  1759,  1103,  1236,   170,  1363, 25766,  1431,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] works the way a good noir should [SEP]\n",
      "torch.Size([1, 35]) tensor([[  101,  1114,   169, 11518,  1111,  1884,  7776, 16405,   117,   112,\n",
      "          1940,  7147,  1883,   182, 15626,  1162,  3114,  1366,  1103,  3264,\n",
      "          2547,  1553,  1111,   170,  1569,  3771,  1164,  3832,   117,  4289,\n",
      "           117,  1105,  2945,   119,   102]], device='cuda:0')\n",
      "[CLS] with ` bowling for columbine,'michael moore gives us the perfect starting point for a national conversation about guns, violence, and fear. [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 22593, 21449,  1133,   102]], device='cuda:0')\n",
      "[CLS] flawed but [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  6019,  1105, 17873,   102]], device='cuda:0')\n",
      "[CLS] distinguished and thoughtful [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,  5342,  1107,   170,  1843,  7172,  1515,   170, 12178,  1164,\n",
      "          2213,  7678,   102]], device='cuda:0')\n",
      "[CLS] stuck in a dark pit having a nightmare about bad cinema [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1114,  1126, 13006,  1107,  8178, 12924,  3452,  6593,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] with an utterly incompetent conclusion [SEP]\n",
      "torch.Size([1, 3]) tensor([[ 101, 1309,  102]], device='cuda:0')\n",
      "[CLS] never [SEP]\n",
      "torch.Size([1, 38]) tensor([[  101,  1167,  1190,  1147,  3527, 15417,   117,  1313,  2523,  1110,\n",
      "          1164,  1103,  1234,  1150,  1686,  1107,  1172,   117,  1150,  1138,\n",
      "          7470,  1147,  1319,  6062, 20545,  1107,  1103,  1362,  1105,  1138,\n",
      "          1151,  1912,  1536,  1106,  2934,  1122,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] more than their unique residences, home movie is about the people who live in them, who have carved their own comfortable niche in the world and have been kind enough to share it. [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101, 1110, 1253, 3869, 4510,  119,  102]], device='cuda:0')\n",
      "[CLS] is still worth hearing. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  7310,   117, 13280, 27547, 24226,  2109,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] wonderful, imaginative [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 3403, 1104, 3007, 1137, 1256,  170, 4928,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] search of purpose or even a plot [SEP]\n",
      "torch.Size([1, 27]) tensor([[  101,   170,  2213, 24034, 27696,  6730,   117,  1103, 26558,  1193,\n",
      "          1637,  2650, 26084,  2165,  1113, 21359, 24348,  1193,  1164,  1147,\n",
      "          2491,   117,  7871,  1105,  1103,  1893,   102]], device='cuda:0')\n",
      "[CLS] a bad improvisation exercise, the superficially written characters ramble on tediously about their lives, loves and the art [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,  8807,   170,   176,  5997, 11944,  1133, 15574, 12522,  1222,\n",
      "         15920,   117,   102]], device='cuda:0')\n",
      "[CLS] bears a grievous but obscure complaint against fathers, [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101, 12283,   188,  5114, 13617,   102]], device='cuda:0')\n",
      "[CLS] surprisingly shoddy [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 1157, 1211, 5670, 1105, 1211, 5119, 4687,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] its most immediate and most obvious pleasure [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,   191, 13292, 10555,   102]], device='cuda:0')\n",
      "[CLS] vibrance [SEP]\n",
      "torch.Size([1, 33]) tensor([[  101,   117,  1126,  2811,  1142,  8362,  7147, 18502,  7698,  2716,\n",
      "          2712,  1156,  1138,   170,   187, 10051,  1818,  2744,  8243,  1114,\n",
      "          6459,  1176,   169,   169,  1873,  1107,  2927,   108,   124,   119,\n",
      "           112,   112,   102]], device='cuda:0')\n",
      "[CLS], an actor this uncharismatically beautiful would have a résumé loaded with credits like ` ` girl in bar # 3.'' [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  3644,  1142,  1176,  1103, 18410,  1174,  2226,  3058,  8925,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] avoid this like the dreaded king brown snake [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  6893,   117,   187,  3984,  2528,  1361,  1193, 21124,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] touching, raucously amusing [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101,  170, 2846, 1159,  102]], device='cuda:0')\n",
      "[CLS] a difficult time [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  3114,  1122,   170,   171, 11848,  6582,  1204,  6779,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] gives it a buoyant delivery [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,   170,  1541,  1363, 20197,   102]], device='cuda:0')\n",
      "[CLS] a really good premise [SEP]\n",
      "torch.Size([1, 16]) tensor([[ 101, 2256, 1107, 1117, 1268, 1713, 1156, 1256, 1341, 1106, 1294, 1103,\n",
      "         8322,  170, 2523,  102]], device='cuda:0')\n",
      "[CLS] anyone in his right mind would even think to make the attraction a movie [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 4133, 1105, 1957,  118, 2199, 2114,  102]], device='cuda:0')\n",
      "[CLS] ideas and special - interest groups [SEP]\n",
      "torch.Size([1, 3]) tensor([[ 101, 8327,  102]], device='cuda:0')\n",
      "[CLS] shallow [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1218,   118,  1694, 12361, 11826,   102]], device='cuda:0')\n",
      "[CLS] well - done supernatural thriller [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 27242,  6814,   102]], device='cuda:0')\n",
      "[CLS] menacing atmosphere [SEP]\n",
      "torch.Size([1, 17]) tensor([[  101,  1223, 19596,  1181,  3853,  1104,   113, 24498, 11437,  8401,\n",
      "         15590,   112,   188,   114,  1578,   119,   102]], device='cuda:0')\n",
      "[CLS] understated performances of ( jack nicholson's ) career. [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,   189, 27577,  1149,  1104,  1103,  5184,  2296,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] trudge out of the theater feeling [SEP]\n",
      "torch.Size([1, 36]) tensor([[  101,  6146,   170,   188,  1732,  7435,  5745,  1183,   117,  1118,\n",
      "           118,  1103,   118,  2849,  6376,  3789,   117,  6146,   170,  8327,\n",
      "           187, 14088,  9199,  1113,  1103, 27781,  1104,  2244,   118,   118,\n",
      "          1105,  3665,  3960,  2008,   119,   102]], device='cuda:0')\n",
      "[CLS] partly a schmaltzy, by - the - numbers romantic comedy, partly a shallow rumination on the emptiness of success - - and entirely soulless. [SEP]\n",
      "torch.Size([1, 3]) tensor([[  101, 10144,   102]], device='cuda:0')\n",
      "[CLS] gorgeous [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101,  117, 1128,  112, 1325, 5548, 1142, 2523,  119,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS], you'll enjoy this movie. [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,   172, 26567,  1181,  8556,  1105,  1679, 10840, 13936, 25265,\n",
      "          1863,   102]], device='cuda:0')\n",
      "[CLS] cliched dialogue and perverse escapism [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1720, 23902,  1107,   170,  1868,  6919,  1233,  2095,  7954,\n",
      "          1273,   102]], device='cuda:0')\n",
      "[CLS] nothing distinguishing in a randall wallace film [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1250,   118,   118,  1110, 14186,   102]], device='cuda:0')\n",
      "[CLS] work - - is charming [SEP]\n",
      "torch.Size([1, 18]) tensor([[  101,  1674,   170,  1632,  4612,  2496,  1112, 12790,   117,   179,\n",
      "          5773,  2944,  6907,  1105,  2548,   118,   118,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] does a great combination act as narrator, jewish grandmother and subject - - [SEP]\n",
      "torch.Size([1, 30]) tensor([[  101,  1110,  3513,  1118,  2849,   117,  1105,  1112,  3123,  1106,\n",
      "          1129, 11920,  1118,  1112,  1240,   170,  1830,  1665,   112,   188,\n",
      "           117,  2693,   170,  1374,  1150, 13044, 22567,  1116,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] is murder by numbers, and as easy to be bored by as your abc's, despite a few whopping shootouts. [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1400,  1103, 12418,  6540,   117,  1133,  1136,  1103, 16570,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] got the brawn, but not the brains [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101,  1167, 17119,   102]], device='cuda:0')\n",
      "[CLS] more meaningful [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101, 10192,  1103,  2960,   118,  1104,   118,  2209,  8492,  1115,\n",
      "          1195,  1225,  1120, 10439,   102]], device='cuda:0')\n",
      "[CLS] possess the lack - of - attention span that we did at seventeen [SEP]\n",
      "torch.Size([1, 20]) tensor([[ 101,  170, 4600,  185, 1174, 6512, 8871, 1241, 1107, 1524, 1104, 1105,\n",
      "          117, 1167, 4418,  117, 1481, 1103, 4504,  102]], device='cuda:0')\n",
      "[CLS] a solid pedigree both in front of and, more specifically, behind the camera [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 15543,  1634,   102]], device='cuda:0')\n",
      "[CLS] inferior level [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1106, 5194, 1103, 3974, 1115, 1189, 1122, 1155, 1250,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] to add the magic that made it all work [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101,  1256,  1191,  1128,  1202,   183,   112,   189,  1221,  1103,\n",
      "          1467,  1137,  1103,  1312,   112,   188,  2040,  1118,  1762,   117,\n",
      "          1128,  1209,  5548,  3195,  1293,  1241, 23530,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] even if you don't know the band or the album's songs by heart, you will enjoy seeing how both evolve [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101, 1105, 1713, 1638,  102]], device='cuda:0')\n",
      "[CLS] and mind games [SEP]\n",
      "torch.Size([1, 23]) tensor([[  101,  1115, 24181,  1566,  1110,   183,   112,   189,  1304,  3999,\n",
      "           117,  1133,  1115,  1131,  1144,   183,   112,   189,  1151,  3869,\n",
      "         12605,  1164,   102]], device='cuda:0')\n",
      "[CLS] that kate isn't very bright, but that she hasn't been worth caring about [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1110,  1250,  1399, 10318,  1107,  1103,  6122,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] is workmanlike in the extreme. [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1111, 2490,  102]], device='cuda:0')\n",
      "[CLS] for everyone [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  3093,  1107,  3121,  3080, 14459,  1118,  1241,  1123,  2548,\n",
      "          2187,  1105,  1103,  1669, 26452,  1116,  1104,  1142,  1963,  7006,\n",
      "          1154,  1103,  5900,  1671,   119,   102]], device='cuda:0')\n",
      "[CLS] seems intimidated by both her subject matter and the period trappings of this debut venture into the heritage business. [SEP]\n",
      "torch.Size([1, 21]) tensor([[  101,  1132, 20186,   119,   119,   119,  1150,  1547,  1129, 11353,\n",
      "          1118,  1103,  2523,   112,   188,  3613,  5172,  1105,  3807,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] are infants... who might be distracted by the movie's quick movements and sounds. [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101,   112,   188,  1103,  3264,  2851,  3686,  1111,  5721,   117,\n",
      "          3525,  1140,  1106,  1921,  1815,  1283,  1121,  1117,  4400,   171,\n",
      "         17776,   117,  3661,   118,  4353,  3251, 20122,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS]'s the perfect star vehicle for grant, allowing him to finally move away from his usual bumbling, tongue - tied screen persona [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  4809,  1193,  5936,  1120,  1436,  1105,  1713,   118,  9769,\n",
      "          7678,  2941, 11738,   102]], device='cuda:0')\n",
      "[CLS] sickly entertainment at best and mind - destroying cinematic pollution [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1304,  4736,  1105, 17090,   119,   102]], device='cuda:0')\n",
      "[CLS] very stupid and annoying. [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101,  170, 4296, 2305, 1104, 2810,  102]], device='cuda:0')\n",
      "[CLS] a tiny sense of hope [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101,  170, 1558, 5671,  102]], device='cuda:0')\n",
      "[CLS] a major waste [SEP]\n",
      "torch.Size([1, 37]) tensor([[  101,  1103,  7584,  1104,  1155, 10434,  1110, 19957,   175, 22940,\n",
      "          2433,  1164, 18686,  1105,  5618,   117,  1134, 20681,  1122,  1104,\n",
      "          1103,  7271,  9556,  1115,  1156,  5854,  1366,  1107,  1412,  6954,\n",
      "           113,  1137,  7678,  3474,   114,   119,   102]], device='cuda:0')\n",
      "[CLS] the sum of all fears is remarkably fuddled about motives and context, which drains it of the dramatic substance that would shake us in our boots ( or cinema seats ). [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101, 1223,  118, 3768,  102]], device='cuda:0')\n",
      "[CLS] under - inspired [SEP]\n",
      "torch.Size([1, 30]) tensor([[ 101, 1128, 1631, 1363,  117, 1128, 1631, 6782,  117, 1128, 1631, 9254,\n",
      "         1228,  117, 1133, 1107, 1103, 1322,  117, 1128, 1631, 3534,  118, 1134,\n",
      "         1110, 1184, 1152, 1225,  119,  102]], device='cuda:0')\n",
      "[CLS] you feel good, you feel sad, you feel pissed off, but in the end, you feel alive - which is what they did. [SEP]\n",
      "torch.Size([1, 58]) tensor([[  101,   170,  5012, 14827,  2212,  1210,  4397,  1104,  9178,  1116,\n",
      "         24887, 11019, 20377,  2692,  1663,  1105,  1607,   117,  1107,  1134,\n",
      "          1195,  1631,  1115,  1195,  5098,  1221,  1184,  2228, 16358,  6071,\n",
      "          1105, 12477,  9324,   189,  5345,   117,  1105,  1412, 12261,  1301,\n",
      "          1149,  1106,  1172,  1112,  1241,  2760,  1106, 14169,  1147, 24034,\n",
      "          1200, 11916,   117,  1567,   118,  4819,  2398,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] a journey spanning nearly three decades of bittersweet camaraderie and history, in which we feel that we truly know what makes holly and marina tick, and our hearts go out to them as both continue to negotiate their imperfect, love - hate relationship [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,   170,  8000, 20497, 11687,  8609, 24034, 10294,  2599,  2165,\n",
      "          4824,  7864,   102]], device='cuda:0')\n",
      "[CLS] a relaxed firth displays impeccable comic skill [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 10928,  4772,   102]], device='cuda:0')\n",
      "[CLS] cheapened [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1126, 15021,   117,  1191,  4444,  3137,   117, 11826,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] an entertaining, if ultimately minor, thriller. [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,   117,  1122,  1431,  2653,  1231, 17482,  6006,  1106,  6827,\n",
      "           119,   102]], device='cuda:0')\n",
      "[CLS], it should pay reparations to viewers. [SEP]\n",
      "torch.Size([1, 3]) tensor([[ 101, 5425,  102]], device='cuda:0')\n",
      "[CLS] guilty [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1202, 3171, 1228, 1219, 1142, 1141,  102]], device='cuda:0')\n",
      "[CLS] doze off during this one [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1110,  183,  112,  189, 1380, 1106, 1129, 1678, 5536,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] isn't something to be taken seriously [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1674,  1177,  1443,  3254,  1643, 16071,  7131,  1115, 12133,\n",
      "           119,   102]], device='cuda:0')\n",
      "[CLS] does so without compromising that complexity. [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101, 18055,  1116,  1155,  4758,  1104, 25492,  5936,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] absorbs all manner of lame entertainment [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  1112,  1103,  2793,   170, 14527,  2042,  1273,  1488,  1104,\n",
      "          1103, 12187,  6393,  1366,  1115,   170,  1631,   118,  1363,  2523,\n",
      "          1169,  1253,  1437,  1842,  1762,   102]], device='cuda:0')\n",
      "[CLS] as the recent argentine film son of the bride reminded us that a feel - good movie can still show real heart [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1103, 6477,  102]], device='cuda:0')\n",
      "[CLS] the mess [SEP]\n",
      "torch.Size([1, 37]) tensor([[  101,  1199,  5558,  1127,  1189,  1111,  1103,  1992,  3251,   117,\n",
      "          1199,  1111,  1103,  1353,  3251,   117,  1105,  1199,   117,  1176,\n",
      "         24244,   131,   174,  8770,  5016,   119, 14516,  4121,   117,  1127,\n",
      "          1189,  1111,  1103,  5824,  3251,   119,   102]], device='cuda:0')\n",
      "[CLS] some movies were made for the big screen, some for the small screen, and some, like ballistic : ecks vs. sever, were made for the palm screen. [SEP]\n",
      "torch.Size([1, 20]) tensor([[  101,  1103,  2030,   118,  1285,  4276,  1116,  1138,  1720,  1113,\n",
      "          1292,  3713,  1165,  1122,  2502,  1106, 10083,  1116,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the modern - day royals have nothing on these guys when it comes to scandals. [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 3439, 1115, 1674, 1136, 1815,  119,  102]], device='cuda:0')\n",
      "[CLS] picture that does not move. [SEP]\n",
      "torch.Size([1, 20]) tensor([[  101,   169,   169,  1177,  2180, 12298,  3287,   112,   112,  1108,\n",
      "          4106, 12682,   117,  1105,  1115,  2523,  1108,  2785,  2213,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] ` ` sorority boys'' was funnier, and that movie was pretty bad [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1900,  1940,  7147,  1883, 11019,  2528,  6582,  7221,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] director michael cacoyannis [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1160,  5167,  6922,  1193,  8406, 17209, 18251,  1116,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] two flagrantly fake thunderstorms [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1106,  2561,   170,  2672,  1273,  1115,  1110, 13273,  1193,\n",
      "          4106,  1106,  2824,   102]], device='cuda:0')\n",
      "[CLS] to create a feature film that is wickedly fun to watch [SEP]\n",
      "torch.Size([1, 18]) tensor([[  101,  9004,  1113,  1157,  1319,  9692,  1757,   118,   118,  1105,\n",
      "          4816,  8734, 10097,  1157,  2712,  1535,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] founders on its own preciousness - - and squanders its beautiful women. [SEP]\n",
      "torch.Size([1, 27]) tensor([[  101,  1110,   170,  4841,  6198,  1186,  1683,  1104, 11339,   117,\n",
      "          1107,  1665,   119,   117,  1443,  1103,  2985,   112,   188, 10405,\n",
      "           117,  5173, 11967,  1137, 16117,   119,   102]], device='cuda:0')\n",
      "[CLS] is a subzero version of monsters, inc., without the latter's imagination, visual charm or texture. [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101, 3960, 2365, 1718,  102]], device='cuda:0')\n",
      "[CLS] soulful development [SEP]\n",
      "torch.Size([1, 35]) tensor([[  101,   170, 21800,  1106,  2267,  1146,  1103,  1864,  1115,  1103,\n",
      "          3439,  1110,  3033,  1213,   170,  4160,  1104, 22593, 25936,  1183,\n",
      "           118,   118,  1137,   117,  4146,  1870,   117,  3839,  8745, 15874,\n",
      "          1204,   118,   118,  4133,   102]], device='cuda:0')\n",
      "[CLS] a tactic to cover up the fact that the picture is constructed around a core of flimsy - - or, worse yet, nonexistent - - ideas [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  6029,  1193, 25876,   102]], device='cuda:0')\n",
      "[CLS] uniformly superb [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  4534, 10195,  1144,   170, 10706,  1895,  3879,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] neither protagonist has a distinguishable condition [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,   173, 11811,  1616, 26453,   102]], device='cuda:0')\n",
      "[CLS] dreary expanse [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1111,  2842,  3254,  7136, 12948,  1116,  1178,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] for dance completists only. [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101,  176, 5697, 2165,  102]], device='cuda:0')\n",
      "[CLS] grumble [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1443,  1251,  1894,  3051,  5031,  2860, 20748,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] without any redeeming value whatsoever. [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   185,  2858, 15977,  8439,  4677,   102]], device='cuda:0')\n",
      "[CLS] plodding soap opera [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1167,  1104,   170, 15751,  1190,   170,  9382,  3958,   117,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] more of a poetic than a strict reality, [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,   112,   188,  1315,  1263,  1105,  8362, 14467,  6697,  1174,\n",
      "           102]], device='cuda:0')\n",
      "[CLS]'s too long and unfocused [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1111,  1157, 12002,  1193, 15302,  1440,  1105,  1839,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] for its elegantly colorful look and sound [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   181, 17294,  1665, 13149,  1105,   102]], device='cuda:0')\n",
      "[CLS] ludicrous and [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   179,  6354,   192, 13276,  1105,   102]], device='cuda:0')\n",
      "[CLS] jane wyman and [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1719, 1429, 1551, 1315, 1242, 1137, 1950, 1315, 1374,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] either 11 times too many or else too few [SEP]\n",
      "torch.Size([1, 31]) tensor([[  101,  1103,  5444,  1144,  1750,   188, 15633,  1190,   170, 11631,\n",
      "           171, 23872,  1105,  1103,  2067,   112,   188,  2935,  4196,  1132,\n",
      "          1167,  1107,  1413,  1114,   188,  1566,  7912,  2343,  6997,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] the script has less spice than a rat burger and the rock's fighting skills are more in line with steven seagal. [SEP]\n",
      "torch.Size([1, 16]) tensor([[  101,  1141, 11019,   183,   112,   189,  1494,  1133,  1129,  3795,\n",
      "          1107,  1118,  1103, 13493,  2650,   102]], device='cuda:0')\n",
      "[CLS] one can't help but be drawn in by the sympathetic characters [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1281,  118,  118, 1105,  102]], device='cuda:0')\n",
      "[CLS] won - - and [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101,   170, 14475,  1104,  5102,  7782,  5936,   117, 12580, 20787,\n",
      "          1105, 13516,  9429,  1902,   102]], device='cuda:0')\n",
      "[CLS] a confluence of kiddie entertainment, sophisticated wit and symbolic graphic design [SEP]\n",
      "torch.Size([1, 33]) tensor([[  101,  1110,  1177, 10666,  1105, 21128,  1105,  6276,  1105,  9189,\n",
      "          1193,  2191,   118,  8387,  1115,  1122,  2228,  1211,  1104,  1184,\n",
      "          4488,  1111,  2673,  1107,  1103,  5558,  1440,  1176, 10928,   177,\n",
      "         21878,  4724,   102]], device='cuda:0')\n",
      "[CLS] is so intimate and sensual and funny and psychologically self - revealing that it makes most of what passes for sex in the movies look like cheap hysterics [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 15880,  2727,   102]], device='cuda:0')\n",
      "[CLS] exploitation piece [SEP]\n",
      "torch.Size([1, 46]) tensor([[  101,   118,   118,  4518,  1487,  4509,  6621,  1104,  1266,   117,\n",
      "         19827,  1105,  1567,  1107,   170,  1207,  1236,   118,   118,   181,\n",
      "         24755,   111,   188,  3121,  6943,  1144,   170,  1295,  1104,  1168,\n",
      "          6661,  1106,  3254,  2354,  1181,  1122,  1106,  2523,  9569,  1241,\n",
      "          7386,  1105,   179, 17535,   119,   102]], device='cuda:0')\n",
      "[CLS] - - putting together familiar themes of family, forgiveness and love in a new way - - lilo & stitch has a number of other assets to commend it to movie audiences both innocent and jaded. [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 12534, 20532,   102]], device='cuda:0')\n",
      "[CLS] upscale [SEP]\n",
      "torch.Size([1, 3]) tensor([[  101, 25677,   102]], device='cuda:0')\n",
      "[CLS] recycled [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,   188,  2340, 10550,  2641,   102]], device='cuda:0')\n",
      "[CLS] stylish cast [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  1131,   118, 10509,   102]], device='cuda:0')\n",
      "[CLS] she - cute [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101, 1110, 1315, 2213,  102]], device='cuda:0')\n",
      "[CLS] is too bad [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1518,  1177, 21620,  1193,   118,   118,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] ever so gracefully - - [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101,  117, 5731, 1904, 1110, 1603,  102]], device='cuda:0')\n",
      "[CLS], 84 minutes is short [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1114,  170, 1297,  118,  170, 3101, 3161, 5031, 3802,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] with a life - affirming message [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 1103, 2960,  118, 1104,  118, 2209, 8492,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the lack - of - attention span [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,   170, 12563,   118, 20787,  1906,  1105, 16688,  6898,   118,\n",
      "          1228,   102]], device='cuda:0')\n",
      "[CLS] a dim - witted and lazy spin - off [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  6270,  3098,  1110,  1136,  1103,  1900,  1120,  1117,  1211,\n",
      "         18439,   102]], device='cuda:0')\n",
      "[CLS] latest effort is not the director at his most sparkling [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101,  178, 6617, 1193, 8431,  102]], device='cuda:0')\n",
      "[CLS] icily brilliant [SEP]\n",
      "torch.Size([1, 17]) tensor([[ 101, 2566, 1508, 5759, 1373, 1702, 1111, 1112, 7926, 1566, 9959, 1105,\n",
      "         1909, 1146, 9153,  119,  102]], device='cuda:0')\n",
      "[CLS] simply putters along looking for astute observations and coming up blank. [SEP]\n",
      "torch.Size([1, 24]) tensor([[  101,   117,  1122,   112,   188,  1126,   184,  4832,  1200, 14194,\n",
      "           117,  8362, 14703, 19828,  1193, 15751, 16910,  1164,  4193,  1105,\n",
      "          8143,  1891,   119,   102]], device='cuda:0')\n",
      "[CLS], it's an observant, unfussily poetic meditation about identity and alienation. [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 12368,  5495,   102]], device='cuda:0')\n",
      "[CLS] engaging mix [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 5805, 1396, 7050, 1785,  118,  118,  102]], device='cuda:0')\n",
      "[CLS] pure venality - - [SEP]\n",
      "torch.Size([1, 18]) tensor([[  101, 11577,  1103,  2927,  1104, 11471,  1144,   183,   112,   189,\n",
      "          1151,  2120,  1807,  3971,   118,  3654,  3976,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] assuming the bar of expectations hasn't been raised above sixth - grade height [SEP]\n",
      "torch.Size([1, 41]) tensor([[  101,  1103,  2523,  1144,   170,  5444,   113,  1118,   185, 18318,\n",
      "          8228,  2692,   114,  1189,  1104,  3591,   117,  1105,  1122,   112,\n",
      "           188, 26011,  1193, 13918,  1183,   117,   170, 16018,  1104,   188,\n",
      "         21365,  1183,  1383,  3423, 18452,  1114, 13480,  4078,  1116,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] the movie has a script ( by paul pender ) made of wood, and it's relentlessly folksy, a procession of stagy set pieces stacked with binary oppositions. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1114,  1940, 26996,  1233, 21608,  6126,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] with miscalculations [SEP]\n",
      "torch.Size([1, 56]) tensor([[  101,  1900,   176, 25690,  2176, 20844, 18738,  1179, 22344,  1200,\n",
      "          1144,  1125,  1199,  2244,  1114, 17221,   117,  1133,  1303,  1117,\n",
      "          2305,  1104,  1642,  1105,  1117, 15031,  4504,  5172, 25767,  1104,\n",
      "           170,  1273,  1278,  1223, 20561,   117,  1105,  1117, 12477,  4867,\n",
      "          2836,  3830,  1547,  1136,  1138,  4690,  1140,  1154,  1273,  1278,\n",
      "          1107,  1103,  1148,  1282,   119,   102]], device='cuda:0')\n",
      "[CLS] director george hickenlooper has had some success with documentaries, but here his sense of story and his juvenile camera movements smack of a film school undergrad, and his maudlin ending might not have gotten him into film school in the first place. [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101,  112,  188,  170, 1304, 5080, 2365, 2067, 1105, 5155, 2523,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS]'s a very tasteful rock and roll movie [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1451,  1420,  1104,  1103,  9525,  1144,  1380, 19601,  1106,\n",
      "          1202,   118,   118,   102]], device='cuda:0')\n",
      "[CLS] every member of the ensemble has something fascinating to do - - [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1868,  3202,  8770,  1157, 12756,  1111,   170,  3613,   118,\n",
      "           171,  8474,  8047,   102]], device='cuda:0')\n",
      "[CLS] ransacks its archives for a quick - buck sequel [SEP]\n",
      "torch.Size([1, 13]) tensor([[ 101,  112,  188, 1145, 3505, 1106, 1267,  170, 2523, 1114, 1157, 1762,\n",
      "          102]], device='cuda:0')\n",
      "[CLS]'s also nice to see a movie with its heart [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1662,  1106,  1294,  1103,  1211,  1104,   170, 26035,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] hard to make the most of a bumper [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101,  1103,  4841, 14657, 10220,  3362,  1110,  1383,  1107,   170,\n",
      "          6456,   170,  2087, 15353,  1179,  8207,  1196,  2765, 11947,   117,\n",
      "          3832,   117,  1105,  1103,  4422, 18785,  2395,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the subtitled costume drama is set in a remote african empire before cell phones, guns, and the internal combustion engine [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1508, 1128, 1106, 2946,  102]], device='cuda:0')\n",
      "[CLS] put you to sleep [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  2228,  1146,  1111,  1107,  1762,  1184,  1122, 14756,  1107,\n",
      "         14484,  1207,  1757,   102]], device='cuda:0')\n",
      "[CLS] makes up for in heart what it lacks in outright newness [SEP]\n",
      "torch.Size([1, 14]) tensor([[ 101, 1103, 2578, 1105, 1103, 1707, 2111, 1132, 1376, 1167, 1190, 9285,\n",
      "          119,  102]], device='cuda:0')\n",
      "[CLS] the material and the production itself are little more than routine. [SEP]\n",
      "torch.Size([1, 37]) tensor([[  101,  1107,  1103,  1842,  1362,   117,  1126,  2811,  1142,  8362,\n",
      "          7147, 18502,  7698,  2716,  2712,  1156,  1138,   170,   187, 10051,\n",
      "          1818,  2744,  8243,  1114,  6459,  1176,   169,   169,  1873,  1107,\n",
      "          2927,   108,   124,   119,   112,   112,   102]], device='cuda:0')\n",
      "[CLS] in the real world, an actor this uncharismatically beautiful would have a résumé loaded with credits like ` ` girl in bar # 3.'' [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1122, 2274, 9820, 1115, 1132, 9009, 1118, 2362, 4473,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] it takes chances that are bold by studio standards [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  1103,  3936,  1200,  5985, 13584,  1103, 15403,  1114,  1177,\n",
      "          1242, 20518,  1105,  1334, 11152, 16721,  1115,  1122,  3769,  1146,\n",
      "          1217, 12283, 10884,   119,   102]], device='cuda:0')\n",
      "[CLS] the transporter bombards the viewer with so many explosions and side snap kicks that it ends up being surprisingly dull. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,   188,  2605,  2007,  1105, 22648,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] snide and prejudice. [SEP]\n",
      "torch.Size([1, 17]) tensor([[  101,  1176,  3208, 20765,   117,  1173,  3316,  2498,  1122,  1113,\n",
      "           117,  1173,  3316,  8362, 21200,  1895,   102]], device='cuda:0')\n",
      "[CLS] like heathers, then becomes bring it on, then becomes unwatchable [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101, 13194,   117,  7271,   117, 16358,  6071,  2615,  4899,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] sweeping, dramatic, hollywood moments [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  2947,  1113,  1111,  1315,  1263,  1105,   171,  8032,  1116,\n",
      "          1205,  1107,   170, 20114, 27863,  1104,  2650,  1105, 14924,  4841,\n",
      "          1643,  7841,  1116,   119,   102]], device='cuda:0')\n",
      "[CLS] goes on for too long and bogs down in a surfeit of characters and unnecessary subplots. [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101,  1211,  1104,  1103, 25869,  1631,  1176,  1159,  5475,  1468,\n",
      "          1206, 20114,  6981,   119,   102]], device='cuda:0')\n",
      "[CLS] most of the storylines feel like time fillers between surf shots. [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  1103,  3811, 22328,   102]], device='cuda:0')\n",
      "[CLS] the earmarks [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 14124,  1193, 19967,   102]], device='cuda:0')\n",
      "[CLS] uncommonly sincere [SEP]\n",
      "torch.Size([1, 16]) tensor([[ 101, 7919, 1106, 1376, 1167, 1190, 9889, 3697, 1111,  170, 2598,  118,\n",
      "         4211, 5367, 1273,  102]], device='cuda:0')\n",
      "[CLS] amounts to little more than preliminary notes for a science - fiction horror film [SEP]\n",
      "torch.Size([1, 14]) tensor([[ 101, 1107, 2213, 1444, 1104, 1558, 3176, 8497, 1105, 2654,  170, 1376,\n",
      "         3538,  102]], device='cuda:0')\n",
      "[CLS] in bad need of major acting lessons and maybe a little coffee [SEP]\n",
      "torch.Size([1, 16]) tensor([[  101,  1106,  1129,   170,  2436,  1678,  1111,  1103, 10475,  1120,\n",
      "          1103,  1322,  1104,  1103,  1437,   102]], device='cuda:0')\n",
      "[CLS] to be a collection taken for the comedian at the end of the show [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1567,  1115,  9778,   170,  1304,  1231,  2142,  2861, 15461,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] love that strikes a very resonant chord [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 2785, 4899,  102]], device='cuda:0')\n",
      "[CLS] pretty moments [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1110,  1260, 17046,  1193,  3014,   117,  5585, 18330,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] is deceptively simple, deeply satisfying [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101, 4090, 8059, 1107, 1103, 2504, 2556, 3750, 1105,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] finds warmth in the coldest environment and [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1169,  1321,  1103,  5372,  2293,  3680,  1137,  1103, 15313,\n",
      "          1105,   102]], device='cuda:0')\n",
      "[CLS] can take the grandkids or the grandparents and [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 1336, 1136, 5194, 1146, 1106, 1103, 7584, 1104, 1157, 2192,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] may not add up to the sum of its parts [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1103, 1509, 1285, 1104, 1103, 1265,  102]], device='cuda:0')\n",
      "[CLS] the final day of the season [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1110,   170,   189, 24157,  1104, 13657,  1116,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] is a trove of delights. [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101, 14255,  4704, 25981,  1158,   102]], device='cuda:0')\n",
      "[CLS] condescending [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 27629, 16936,  1200,   102]], device='cuda:0')\n",
      "[CLS] tardier [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,  1833,  1157, 18777,  6884,   102]], device='cuda:0')\n",
      "[CLS] doing its namesake proud [SEP]\n",
      "torch.Size([1, 30]) tensor([[  101,   117,  1103,  7584,  1104,  1155, 10434, 21241,  1376,  8195,\n",
      "         11550,   117,  1105, 20384,  8362,  2087, 19709,  1158, 21329,  1106,\n",
      "          1168, 20669,  1116,  1107,  1103,   187,  6582,  1326,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS], the sum of all fears generates little narrative momentum, and invites unflattering comparisons to other installments in the ryan series. [SEP]\n",
      "torch.Size([1, 22]) tensor([[  101,  1120,  1551,   170,  2113,  1143,  2858,  7412, 10734,  1105,\n",
      "          1256,   170,  1376,  5422,   113,  5763,  1852,  1187,  1128,  1686,\n",
      "           114,   102]], device='cuda:0')\n",
      "[CLS] at times a bit melodramatic and even a little dated ( depending upon where you live ) [SEP]\n",
      "torch.Size([1, 45]) tensor([[  101,  1103,  3248,  1413,  1114, 24928,  6801,  1548,  1110,  1103,\n",
      "          1269,  1112,  1122,  1144,  1151,  1114,  1155,  1103,  2441,  1107,\n",
      "          1103,  1326,   131,  3899,  1209, 19832,  5548,  1122,   117,  1105,\n",
      "          1103,  8362,  8178,  9084,  1906,  1444,   183,   112,   189,  5671,\n",
      "          1147,  1159,  1113,  1122,   102]], device='cuda:0')\n",
      "[CLS] the bottom line with nemesis is the same as it has been with all the films in the series : fans will undoubtedly enjoy it, and the uncommitted needn't waste their time on it [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101, 9832, 1118, 6135, 2944, 2269, 1105, 3176,  117,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] ruined by amateurish writing and acting, [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101, 14756,  5602,  9304,  2660,   102]], device='cuda:0')\n",
      "[CLS] lacks considerable brio [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,   117, 15021,  3789,   102]], device='cuda:0')\n",
      "[CLS], entertaining comedy [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 1126, 8362, 7767, 3923, 1181, 7759, 1104, 9429, 4127, 8145,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] an unbalanced mixture of graphic combat footage [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 4348, 4333,  102]], device='cuda:0')\n",
      "[CLS] cool stuff [SEP]\n",
      "torch.Size([1, 16]) tensor([[  101,  1644,  5123,  2093,   112,   188,  1166,   118,  1107,  7641,\n",
      "         21463,  2227,   189,  5132,  2007,   102]], device='cuda:0')\n",
      "[CLS] lawrence's over - indulgent tirade [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101, 1110, 6276, 1105,  102]], device='cuda:0')\n",
      "[CLS] is funny and [SEP]\n",
      "torch.Size([1, 35]) tensor([[  101,  1191,  1128,  6239,   195, 12963,   113,  1103,  3676,  1121,\n",
      "           188, 25703,   114,  1122,  1209,  1294,  1128,  3683,  1128,  1127,\n",
      "          1120,  1313,  2903,  1115,  2523,  1939,  1104,  1107,  1103,  5184,\n",
      "          2903,  1142,  1141,   119,   102]], device='cuda:0')\n",
      "[CLS] if you recognize zeus ( the dog from snatch ) it will make you wish you were at home watching that movie instead of in the theater watching this one. [SEP]\n",
      "torch.Size([1, 13]) tensor([[ 101, 1294, 1122, 1440, 1112, 1463, 1152, 1132, 1515, 1177, 1277, 4106,\n",
      "          102]], device='cuda:0')\n",
      "[CLS] make it look as though they are having so much fun [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,   112,   188,  8930,  4824,  1105, 12283,  6893,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS]'s sharply comic and surprisingly touching [SEP]\n",
      "torch.Size([1, 24]) tensor([[  101,  1142, 17562,  8362, 14703, 15863,  1677,  2093,  3404,  1116,\n",
      "          1107,  4871, 26478,  1105,  4035, 19172, 11697,  2111,  1114, 13522,\n",
      "           119,   119,   119,   102]], device='cuda:0')\n",
      "[CLS] this painfully unfunny farce traffics in tired stereotypes and encumbers itself with complications... [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101, 12100,  1116,  4899,  1104, 20061, 24268,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] fosters moments of spontaneous intimacy [SEP]\n",
      "torch.Size([1, 3]) tensor([[ 101, 1817,  102]], device='cuda:0')\n",
      "[CLS] leave [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,   170, 14478,  2436,   102]], device='cuda:0')\n",
      "[CLS] a derivative collection [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 1115, 1119,  112,  188, 1103, 1436, 8415, 1107, 1103, 1671,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] that he's the best brush in the business [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101, 10085,  1183,  4612,  1104,  8439,  4677,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] patchy combination of soap opera [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101, 23978,  1105,   188,  2340, 15105,   102]], device='cuda:0')\n",
      "[CLS] layered and stylistic [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 2059, 1115, 1234, 1138, 1575, 1103, 2912, 1106, 1341, 1105,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] believe that people have lost the ability to think and [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101, 12076,  7363,  4371,  1431,  1831,  1774,  1106,  4268,  1117,\n",
      "          4113,   119,   102]], device='cuda:0')\n",
      "[CLS] shyamalan should stop trying to please his mom. [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1176,  170, 2377, 1273,  102]], device='cuda:0')\n",
      "[CLS] like a student film [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101, 1508, 1283, 1103, 2092,  117,  102]], device='cuda:0')\n",
      "[CLS] put away the guitar, [SEP]\n",
      "torch.Size([1, 17]) tensor([[  101,  3195,  1112,  1103,  1273, 14756, 11550,  1105,  1157,  1700,\n",
      "          2606,  2426,  5576, 24951, 14503,  2165,   102]], device='cuda:0')\n",
      "[CLS] seeing as the film lacks momentum and its position remains mostly undeterminable [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1211, 6432, 2672, 1111, 1199, 1159,  102]], device='cuda:0')\n",
      "[CLS] most substantial feature for some time [SEP]\n",
      "torch.Size([1, 20]) tensor([[ 101, 1106, 1138,  170, 1363, 1159, 1112, 1122, 1202, 2897, 1149, 3423,\n",
      "         1104, 1103, 2505, 1900,  112,  188, 1297,  102]], device='cuda:0')\n",
      "[CLS] to have a good time as it doles out pieces of the famous director's life [SEP]\n",
      "torch.Size([1, 16]) tensor([[ 101, 1110,  170, 9210, 2523,  118,  118, 1191, 1178, 1122, 1127, 1115,\n",
      "         5372,  170, 4290,  102]], device='cuda:0')\n",
      "[CLS] is a horrible movie - - if only it were that grand a failure [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  2482,  1149,  1115,  1142,  1110,   170,   182, 24211,  1320,\n",
      "          1266,  2523,   117,  1105,   170, 21718, 20099,   117,  3073,  7291,\n",
      "          1183,  1141,  1120,  1115,   102]], device='cuda:0')\n",
      "[CLS] figure out that this is a mormon family movie, and a sappy, preachy one at that [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101,  170, 1236, 1115, 1374, 5558, 1138, 1518, 4685,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] a way that few movies have ever approached [SEP]\n",
      "torch.Size([1, 19]) tensor([[  101,   170,  1363,   118,  2731,  1181,  9525,  3789,  1115,  4642,\n",
      "          1662,  1106,  1294,  1103,  1211,  1104,   170, 26035,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] a good - natured ensemble comedy that tries hard to make the most of a bumper [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  8214,  1348,  1105, 24017,   119,   102]], device='cuda:0')\n",
      "[CLS] banal and predictable. [SEP]\n",
      "torch.Size([1, 32]) tensor([[  101,  1336,  1256,  1525,  1115,  1122,  2947,  1118,  1976,   117,\n",
      "          1272,  1122,  1144,  1199,  1104,  1103,  4106, 16133,  1204, 13948,\n",
      "          1104,  1251,  2523,  1142,  1214,   117,  1259,  1343,  3005,  1111,\n",
      "          6323,   102]], device='cuda:0')\n",
      "[CLS] may even find that it goes by quickly, because it has some of the funniest jokes of any movie this year, including those intended for adults [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101, 24034,  2944, 23448,  6620,  2217,  1880,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] impish divertissement [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,  1129, 22572,  9866, 10680,   102]], device='cuda:0')\n",
      "[CLS] be cherished [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1112,   182, 14824,  2217,  1112, 13964, 10203,   117,  9372,\n",
      "          1105,  6321,  3513,   102]], device='cuda:0')\n",
      "[CLS] as morose as teen pregnancy, rape and suspected murder [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101,  119,  119,  119, 1110, 3840, 3680, 2138,  119,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS]... is dudsville. [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,   173, 11811,  1616,  1105,  1166,  2246, 14929,  1204,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] dreary and overwrought [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1817, 1122,  102]], device='cuda:0')\n",
      "[CLS] leave it [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  3254, 16091, 27199,  1193,  2824,  1895,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] compulsively watchable [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 3216, 1146,  102]], device='cuda:0')\n",
      "[CLS] mixed up [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101, 1110,  170, 3840, 1181,  119,  102]], device='cuda:0')\n",
      "[CLS] is a dud. [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101, 1114,  170, 9839, 1106, 1322, 1155, 9839, 1116,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] with a chase to end all chases [SEP]\n",
      "torch.Size([1, 20]) tensor([[ 101, 1138, 2423, 6278, 1103, 2523, 1118, 1103, 1159, 1128, 1243, 1171,\n",
      "         1106, 1240, 1610, 1107, 1103, 5030, 1974,  102]], device='cuda:0')\n",
      "[CLS] have completely forgotten the movie by the time you get back to your car in the parking lot [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  1114,  1185, 25946,   102]], device='cuda:0')\n",
      "[CLS] with no aspirations [SEP]\n",
      "torch.Size([1, 19]) tensor([[  101,  1103,  1642,  1110,  1198,  1315,   172, 16879,  2744,  1181,\n",
      "          1105,  1315,  1510, 21116,   172,  4359, 15818,  2340,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the story is just too clichéd and too often strains credulity [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  3839,  1104,  1142,  3807, 10480,  1105,   117,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] none of this sounds promising and, [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101, 22052,  2285,   117, 16664, 21462,  2285,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] outrageous, ingenious [SEP]\n",
      "torch.Size([1, 29]) tensor([[  101,  4061,  1253,  1107,  1167,  3242,  1115,  1141,  1107, 24998,\n",
      "          9870,  6206,   117,   170,   188,  6617,   118, 20497, 11826,  1112,\n",
      "         16688,  1112,  1122,  1110,  9455, 14503,  2165,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] stands still in more ways that one in clockstoppers, a sci - fi thriller as lazy as it is interminable. [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  1141,  2255,  1122,   112,   188,  1177,  2960, 23225,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] one reason it's so lackluster [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1133, 1273,  171, 9435, 1116, 1431, 1243, 1106, 1221,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] but film buffs should get to know [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  3321,  1193, 13280, 27547, 24226,  2109,  1105,  2265,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] hugely imaginative and successful [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 21371,  2099,   102]], device='cuda:0')\n",
      "[CLS] stellar performance [SEP]\n",
      "torch.Size([1, 32]) tensor([[  101,  1900,  1106, 13976,  3444,  3276,  1584,  1144,  1189,   170,\n",
      "          2523,  1164,  3607,  3943,  1106,  1117,  1160,  2166,  5558,   117,\n",
      "          1105,  1164,  1117,  4812,  1106,  1103,  2650,  1115,  1119,  8743,\n",
      "           119,   102]], device='cuda:0')\n",
      "[CLS] director todd solondz has made a movie about critical reaction to his two previous movies, and about his responsibility to the characters that he creates. [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  9007,  1174,  4783,  1118,  1141,   118, 12119,  1116,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] elbowed aside by one - liners [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1363, 11078,  4558,   118,  6898,  2511,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] good yarn - spinner [SEP]\n",
      "torch.Size([1, 20]) tensor([[  101,  1525,   182,  1766,  4889,  1320,   112,   188, 15802, 13335,\n",
      "         20519,  2745,  1104,  2815,  1106,  1129,   181, 24851,  3798,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] find morrison's iconoclastic uses of technology to be liberating [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  2493,  1200,  1105,  1884,   118,  2432,  5855,  4679,  2042,\n",
      "          4267, 22956, 11014,  1132, 12969,  1106,  1143,  1233,  2138,   112,\n",
      "           188,  4928,  2568,   117,  1152,   102]], device='cuda:0')\n",
      "[CLS] parker and co - writer catherine di napoli are faithful to melville's plotline, they [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101, 13445,  1633,  9414,  1116,  1103,  5444,   112,   188, 24132,\n",
      "          1105,  4035, 12559,  9706,  1103,  3703,  1107,  1117,  1959,   112,\n",
      "           188, 25096,   117,  4470,  1105,  9074,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] washington overcomes the script's flaws and envelops the audience in his character's anguish, anger and frustration. [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,   170, 14478,  2436,  1104,  5367,  1105,   188,  6617,   118,\n",
      "         20497,   102]], device='cuda:0')\n",
      "[CLS] a derivative collection of horror and sci - fi [SEP]\n",
      "torch.Size([1, 33]) tensor([[  101,  1679,  3263,  5430,  1155,  1157,  5402,   118,   118,  1121,\n",
      "          1103,   189,  1964,  2523,   118, 13936,  3530,   117,  4634,  2027,\n",
      "          3176,  1106,  1103, 10884,  2556,   178,  4889,  1324, 11030,  4429,\n",
      "          1518,  5819,   102]], device='cuda:0')\n",
      "[CLS] permeates all its aspects - - from the tv movie - esque, affected child acting to the dullest irish pub scenes ever filmed [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1155,  1103, 26563, 10881,  1105,   102]], device='cuda:0')\n",
      "[CLS] all the sibling rivalry and [SEP]\n",
      "torch.Size([1, 5]) tensor([[ 101,  169, 6892,  112,  102]], device='cuda:0')\n",
      "[CLS] ` gentle'[SEP]\n",
      "torch.Size([1, 21]) tensor([[  101,  1110,  1136,  1437,   118,  7202,  1193, 20844,  5815,  4179,\n",
      "           117,  1133,   188, 12650,  8840,  1193, 20787,  2340, 14642,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] is not show - stoppingly hilarious, but scathingly witty nonetheless. [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1103, 3057, 7762, 1116,  102]], device='cuda:0')\n",
      "[CLS] the cultural distinctions [SEP]\n",
      "torch.Size([1, 7]) tensor([[ 101, 1328, 1139, 1948, 1171,  119,  102]], device='cuda:0')\n",
      "[CLS] want my money back. [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  1253,   117,  1103,  8054, 14458,  5026,  1811, 14516,  2316,\n",
      "          7706,  1104,  2432,   172, 14089,  1403,  2927,  5034,  3069,   112,\n",
      "           188,  1642,  1110, 17117,   119,   102]], device='cuda:0')\n",
      "[CLS] still, the updated dickensian sensibility of writer craig bartlett's story is appealing. [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 5110,  117, 3793,  117, 1107,  118, 8155, 1183, 1141,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] hip, contemporary, in - jokey one [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  1114,   182, 14566,  1605,  6289,  2254,  1107,  1126,  3665,\n",
      "         23027,   118,  1714,  4834,  1105,   171,  7531,  3549,  2871,  1106,\n",
      "          9698,  1117,  7246, 17710,   102]], device='cuda:0')\n",
      "[CLS] with mcconaughey in an entirely irony - free zone and bale reduced mainly to batting his sensitive eyelids [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  4607,  1116,  1113,  1122,   117,  1114, 21359, 14791, 21361,\n",
      "          2775,  9043,   117,  1107, 14850,  2109,  2168, 10028,  1105,   170,\n",
      "           173, 10747,  2305,  1104,  8594,   102]], device='cuda:0')\n",
      "[CLS] improves on it, with terrific computer graphics, inventive action sequences and a droll sense of humor [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,  1103,  8262,  1110, 14449,   102]], device='cuda:0')\n",
      "[CLS] the artwork is spectacular [SEP]\n",
      "torch.Size([1, 19]) tensor([[  101,  4358,  1231, 13782,  5430,  1241,  1103,  2952,  3545,  1105,\n",
      "          6438, 14696,  1104,  1103,   185, 11478,  1394,  5919,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] successfully recreates both the physical setting and emotional tensions of the papin sisters [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101, 16664, 21462,  2285,  4106,   102]], device='cuda:0')\n",
      "[CLS] ingenious fun [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 10509,  5821, 24727,   102]], device='cuda:0')\n",
      "[CLS] cutesy reliance [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  2472, 21813,  1105, 19681,  8755,  1107,  2996,  9304,  9753,\n",
      "          8068,   118,   118,   188, 15903,   172, 26567,  1116,   117,   176,\n",
      "          7625, 10950,  2285,  4289,   102]], device='cuda:0')\n",
      "[CLS] street gangs and turf wars in 1958 brooklyn - - stale cliches, gratuitous violence [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  9440,  1106,  1157, 13336,  1184,   118,  1191,  3400,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] rises to its clever what - if concept. [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  3229,  1103, 10272,  2556,  2523,  1518,  1189,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] perhaps the grossest movie ever made. [SEP]\n",
      "torch.Size([1, 27]) tensor([[  101, 10144,  1106,  1440,  1120,  1133, 22233,  9435,  5970,  4999,\n",
      "         21359, 24348,  1105,   189, 15243,  2386,   119,   119,   119,   170,\n",
      "         18941, 14255,  2050, 20288, 11431,   119,   102]], device='cuda:0')\n",
      "[CLS] gorgeous to look at but insufferably tedious and turgid... a curiously constricted epic. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1122,   112,   188, 25338,  1361,  1183,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] it's lousy [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101,   112,   188,  1112, 16401,  1183,  1112,  1160,   118,  1285,\n",
      "          1385,   185,  1766,  8044,   102]], device='cuda:0')\n",
      "[CLS]'s as lumpy as two - day old porridge [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  9645,  4289, 17074,  9574, 11997,  1917,   117,  1259,  1211,\n",
      "          1104,  1103,  5681,   102]], device='cuda:0')\n",
      "[CLS] staged violence overshadows everything, including most of the actors [SEP]\n",
      "torch.Size([1, 4]) tensor([[ 101, 1114, 3960,  102]], device='cuda:0')\n",
      "[CLS] with soul [SEP]\n",
      "torch.Size([1, 48]) tensor([[  101,  1157,  1642,  1164,   170,  1685,  5144,  6420,  1590,   117,\n",
      "         18257,  9468,   117,  1150,  1144,  1435,  1106,  1207, 26063,  4661,\n",
      "          1331,  1106,  4971,  1763, 12343,  1114,  1103,  1821, 26237,  1389,\n",
      "          4185,  1110,  1141,  1115,  1251,  1893,   118,  1402,  2523,  2758,\n",
      "          1200,  1110,  2620,  1106,  1525, 18397,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] its story about a young chinese woman, ah na, who has come to new york city to replace past tragedy with the american dream is one that any art - house moviegoer is likely to find compelling. [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 1103, 3251,  118,  118, 4632,  117, 5973, 1105, 1713, 2008,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the screen - - loud, violent and mindless [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 1185, 8362, 8985, 6795, 1137, 5173, 1947,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] no unifying rhythm or visual style [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 1175, 1110, 9692, 1376, 1104, 1719,  119,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] there is precious little of either. [SEP]\n",
      "torch.Size([1, 20]) tensor([[ 101,  192, 1186,  183,  112,  189, 1138, 1251, 3819, 2033, 4067, 1106,\n",
      "         3940, 1146, 1292, 1396, 9705, 1905,  119,  102]], device='cuda:0')\n",
      "[CLS] won't have any trouble getting kids to eat up these veggies. [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   184, 17395,  1279,  8315,   119,   102]], device='cuda:0')\n",
      "[CLS] oozes craft. [SEP]\n",
      "torch.Size([1, 27]) tensor([[  101,  2320,  1106,  5233,  1155,  1103,  7893,  1596, 11838,  1107,\n",
      "          1103,  1263,   118,  3223,  1174,  1119,  1776,  3789,  1150,  1110,\n",
      "           172,  5765,  1548,  1106,  3818,   136,   102]], device='cuda:0')\n",
      "[CLS] required to balance all the formulaic equations in the long - winded heist comedy who is cletis tout? [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  1142,  6782,   117,  3254, 16091, 27199,  1297,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] this sad, compulsive life [SEP]\n",
      "torch.Size([1, 17]) tensor([[  101,  1336,  1112,  1218,  1129,  1270,   169,   169, 19609,   118,\n",
      "         19609,  9055,  4616,   131,  1103,  2523,   102]], device='cuda:0')\n",
      "[CLS] may as well be called ` ` jar - jar binks : the movie [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101,  170,  188, 8167, 5773, 1181, 1105, 3903, 1273,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] a shrewd and effective film [SEP]\n",
      "torch.Size([1, 27]) tensor([[  101,  5871,  6540,  1105, 21718, 13141,  1320,  1532,  1126,  3176,\n",
      "          7069,  1115,  2228,  1103, 21260,  1200,  5919,   170, 19601,  1959,\n",
      "          2025,  1114, 12375,  1106,  8608,   119,   102]], device='cuda:0')\n",
      "[CLS] hawn and sarandon form an acting bond that makes the banger sisters a fascinating character study with laughs to spare. [SEP]\n",
      "torch.Size([1, 18]) tensor([[ 101, 1103, 1864, 1115, 1122, 1110,  183,  112,  189, 1304, 1363, 1110,\n",
      "         1593, 3148, 1103, 1553,  119,  102]], device='cuda:0')\n",
      "[CLS] the fact that it isn't very good is almost beside the point. [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   170,  2330,   118,  7074, 26539,   102]], device='cuda:0')\n",
      "[CLS] a clear - eyed chronicle [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1132,   181, 16140, 18900,  1105,  3613,  1106,  2789,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] are lukewarm and quick to pass. [SEP]\n",
      "torch.Size([1, 51]) tensor([[  101,  1344,  6969,  7450,  1593,  1185,  7878,  1107, 19091,  7222,\n",
      "          1112,   170,  1433,   120,  5243,   120,  2732,  8069,   117,  1105,\n",
      "          1115,   112,   188,  1272,  1103,  2523,  3411,  1146,  1155,  1104,\n",
      "          1115,  4333,   117,  2212,  4841, 24891, 14196,  1193,   117,  1112,\n",
      "          1103,  1385,   118,  6131,  3199,  1104,  2581,  1107, 19091,  7222,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] high crimes carries almost no organic intrigue as a government / marine / legal mystery, and that's because the movie serves up all of that stuff, nearly subliminally, as the old - hat province of male intrigue [SEP]\n",
      "torch.Size([1, 32]) tensor([[  101,  1121,  2935,  1638,   117,  7700,   175,  1358,   117,  5367,\n",
      "          5558,   117,  8069,   117, 17462,  1279,  7069,   117,  7325,   117,\n",
      "           188,  6617,   118, 20497,  1105,  9499,  1154,  1141,  1992,  7201,\n",
      "         26036,   102]], device='cuda:0')\n",
      "[CLS] from fighting games, wire fu, horror movies, mystery, james bond, wrestling, sci - fi and anime into one big bloody stew [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  8362,  8178,  1643, 16071,  7131,   102]], device='cuda:0')\n",
      "[CLS] uncompromising [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  3639,  1111,  1126,   184, 26996,  1197,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] nominated for an oscar [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101,  1157, 22239,  3176,   102]], device='cuda:0')\n",
      "[CLS] its exquisite acting [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  6061,   117,  8431,  1105, 23639,  6639,  1874,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] twisted, brilliant and macabre [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,   119,   119,   119, 10228,  1105,  8468, 12606, 12571,   119,\n",
      "           119,   119,   102]], device='cuda:0')\n",
      "[CLS]... wise and elegiac... [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 1111, 1155, 1103, 2488, 3672, 8655,  119,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] for all the wrong reasons besides. [SEP]\n",
      "torch.Size([1, 26]) tensor([[  101,  1103,  5173,  1116,  1105,  4035, 12559, 16391,  3807,  1104,\n",
      "          2221, 11321,  1294,  1142, 12283, 11858, 22302,  3869,   170,  2247,\n",
      "          4974,  1440,   118,  1267,   119,   102]], device='cuda:0')\n",
      "[CLS] the visuals and enveloping sounds of blue crush make this surprisingly decent flick worth a summertime look - see. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1126, 10264,  1273,   117,  1136,  1655,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] an extraordinary film, not least [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,   117,  1763,  1183, 16401,  1424,   102]], device='cuda:0')\n",
      "[CLS], pasty lumpen [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101, 10729,  1105, 19863, 12355, 23901,   102]], device='cuda:0')\n",
      "[CLS] silly and monotonous [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101, 12154,  2952,  2308,  1105,   102]], device='cuda:0')\n",
      "[CLS] explosive physical energy and [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101, 1209, 2620, 1383, 1103, 2612, 1104, 1590, 9171, 1171, 4397,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] will likely set the cause of woman warriors back decades [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1113, 1241, 3091, 1122, 4887, 1603,  102]], device='cuda:0')\n",
      "[CLS] on both sides it falls short [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101, 10884,  1112,  1157,  2650,   117,  1164,  2133,  7012,  1122,\n",
      "          1110,  1662,  1106,  1920,   102]], device='cuda:0')\n",
      "[CLS] dull as its characters, about whose fate it is hard to care [SEP]\n",
      "torch.Size([1, 54]) tensor([[  101,   113,   181,  1394, 22572,  4380,   112,   188,   114,  1490,\n",
      "          1110,  1897, 25731,  1775, 19792,  1348,   117,  1256,   178, 14791,\n",
      "         24558,   113,  1120,  1655,  1106,  1142,  2466,  3811,   114,   117,\n",
      "          1543,  1122,  9684,  1193,  1662,  1106,  4417,  1103, 24034, 16311,\n",
      "          1111,  1103,  8277,  1567, 12099,  1115, 11926,  1206,  1103,  1210,\n",
      "          2129,  2650,   119,   102]], device='cuda:0')\n",
      "[CLS] ( lin chung's ) voice is rather unexceptional, even irritating ( at least to this western ear ), making it awfully hard to buy the impetus for the complicated love triangle that develops between the three central characters. [SEP]\n",
      "torch.Size([1, 30]) tensor([[  101,  1138,  1151,  4106, 12682,  1191,  1103,  1900,  1125,  1308,\n",
      "          1103,  1149, 13482,  1116,  9033,  1193,  1105,  1215,  1103,  1273,\n",
      "          1112,   170,  6992,  2672,  1113,  1103,   173,  1964,  1181,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] have been funnier if the director had released the outtakes theatrically and used the film as a bonus feature on the dvd [SEP]\n",
      "torch.Size([1, 3]) tensor([[ 101, 1748,  102]], device='cuda:0')\n",
      "[CLS] further [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,  6782,  5562,  8295, 22302,   102]], device='cuda:0')\n",
      "[CLS] sadistic bike flick [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 14051,  2008,  3676,   102]], device='cuda:0')\n",
      "[CLS] toothless dog [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1103, 14833, 14061,  2502,  1106,  2789,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the downward spiral comes to pass [SEP]\n",
      "torch.Size([1, 32]) tensor([[  101,  1155,  1103,  3472,   118,  3219,  4289,   117, 15302,  1207,\n",
      "         26063,  4661,  6939, 25338,  1874,  1105,  1168,  2885, 22328,  1104,\n",
      "          1117,  2357,  7678,  4331,  1113,  1147,  2026,   118,  1518,  3009,\n",
      "         11246,   102]], device='cuda:0')\n",
      "[CLS] all the stomach - turning violence, colorful new york gang lore and other hallmarks of his personal cinema painted on their largest - ever historical canvas [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  4642,  1106,   172,  4515,  1315,  1242, 13288,  1154,  1141,\n",
      "          1353,  9814,   119,   102]], device='cuda:0')\n",
      "[CLS] tries to cram too many ingredients into one small pot. [SEP]\n",
      "torch.Size([1, 11]) tensor([[ 101, 1296, 1642, 1110, 1434, 1113,  170, 9046, 5426, 1911,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] each story is built on a potentially interesting idea [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 10966, 18106,   102]], device='cuda:0')\n",
      "[CLS] politically potent [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,  2947,  1187,  1128,  5363,  1105,  1510, 22810,  1128,  1114,\n",
      "          9334,  3789,   102]], device='cuda:0')\n",
      "[CLS] goes where you expect and often surprises you with unexpected comedy [SEP]\n",
      "torch.Size([1, 23]) tensor([[  101,  7189,  1293,  1195,  1155,  1444,   170, 20303,  1231, 20080,\n",
      "          3150,  1121,  1103,  5207,  1181,  1106,  1231,  2087, 21298,  1412,\n",
      "         11191,   119,   102]], device='cuda:0')\n",
      "[CLS] reveals how we all need a playful respite from the grind to refresh our souls. [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  1267,   169,   169,  2221, 11321,   112,   112,  1110,  1103,\n",
      "         14343,  1233,   117,  1447,   118,  1255,  7678, 22556,  1118,  5358,\n",
      "         18312,  1119, 15918,  1116,   102]], device='cuda:0')\n",
      "[CLS] see ` ` blue crush'' is the phenomenal, water - born cinematography by david hennings [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1103, 1436, 5558, 1104, 1103, 1214,  102]], device='cuda:0')\n",
      "[CLS] the best movies of the year [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101,  6806,  1174,  2168, 11826,  1164,  1567,  1105, 12010,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] tooled action thriller about love and terrorism [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1106,  3258,  1103, 12261,  1104,  8794, 23139,  1104,  1155,\n",
      "          6776,   102]], device='cuda:0')\n",
      "[CLS] to warm the hearts of animation enthusiasts of all ages [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1870,  4035, 21932, 23906,  2727,   102]], device='cuda:0')\n",
      "[CLS] yet engrossing piece [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101, 20787,  2340,   117, 18652,   117,  1105,  9998,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] witty, vibrant, and intelligent [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,  1110,  1260, 17046,  1193,  3014,   117,  5585, 18330,   119,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] is deceptively simple, deeply satisfying. [SEP]\n",
      "torch.Size([1, 21]) tensor([[  101,   175,  4047,  2528,  1110,  1126,  6548,  3026,  1111,  1103,\n",
      "         20016,   118,  1228,  1133, 27481,  8954,  5225,   177,  8954,  2879,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] franco is an excellent choice for the walled - off but combustible hustler [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1328, 1106, 1267, 1122,  102]], device='cuda:0')\n",
      "[CLS] want to see it [SEP]\n",
      "torch.Size([1, 22]) tensor([[  101,  1103, 12382,  5099,  4444,  1166, 17731,  1116,  1184,  1376,\n",
      "          1195,  3858,  1373,  1103,  1236,  1164, 19228,  4179,  1894, 19007,\n",
      "           119,   102]], device='cuda:0')\n",
      "[CLS] the corpse count ultimately overrides what little we learn along the way about vicarious redemption. [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1565,  4338,   118,  1947, 16715,  1757,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] sixties - style slickness [SEP]\n",
      "torch.Size([1, 21]) tensor([[  101,  1126, 22695,  2077,  1159,   117,  2709,  1114,  5604,  2308,\n",
      "           117,  7279,  1821,  5567, 13830,  1785,  1105,  1632,  9591,  4338,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] an intensely lived time, filled with nervous energy, moral ambiguity and great uncertainties [SEP]\n",
      "torch.Size([1, 21]) tensor([[  101,  1106, 23220, 16211,   112,   188, 26011,  4470,   117,  1105,\n",
      "          1106,  1103,  5444,   112,   188, 14686,  1104,   170,  2816,  3830,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] to jimmy's relentless anger, and to the script's refusal of a happy ending [SEP]\n",
      "torch.Size([1, 28]) tensor([[  101,  1157,  2934,  1104, 12375,   118,   118,  2121,   170, 16305,\n",
      "           117,  2121,   170,   176,  9435,  7220,  1105,   117,  1106,  1139,\n",
      "          1632,  4687,   117,  1103,  7957,  7413,  4046,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] its share of laughs - - sometimes a chuckle, sometimes a guffaw and, to my great pleasure, the occasional belly laugh [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101, 13198,  1126, 13905,  1111,   170,   112, 19025, 15880,  3439,\n",
      "           102]], device='cuda:0')\n",
      "[CLS] resembles an outline for a'70s exploitation picture [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 22572,  2149, 10550,   102]], device='cuda:0')\n",
      "[CLS] churlish [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101, 27033,  1110,  1762,  8124,  6066,  1105, 15790,  1193,  1842,\n",
      "           119,   102]], device='cuda:0')\n",
      "[CLS] skins is heartfelt and achingly real. [SEP]\n",
      "torch.Size([1, 6]) tensor([[  101,  1126,  5048,  4873, 11826,   102]], device='cuda:0')\n",
      "[CLS] an edgy thriller [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,  1103,  3499, 16955,  1104,  1234,  1150,  2222,  1106,  3359,\n",
      "          1103,  1583,   102]], device='cuda:0')\n",
      "[CLS] the boat loads of people who try to escape the country [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1110,  8362, 10733, 25282,  1193,  5250,   118, 14516, 26281,\n",
      "          1811,   102]], device='cuda:0')\n",
      "[CLS] is unashamedly pro - serbian [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101,   188, 15363,   102]], device='cuda:0')\n",
      "[CLS] slump [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101, 21401,  1116,   117,  1315,  1242, 27836,  1116,  1105,   170,\n",
      "         22572, 27643,  3830,   102]], device='cuda:0')\n",
      "[CLS] thrills, too many flashbacks and a choppy ending [SEP]\n",
      "torch.Size([1, 12]) tensor([[ 101,  112,  188, 1136, 1315, 2698, 1105, 1136, 1315, 3345,  119,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS]'s not too fast and not too slow. [SEP]\n",
      "torch.Size([1, 10]) tensor([[  101, 19609,   118, 19609,  9055,  4616,   131,  1103,  2523,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] jar - jar binks : the movie [SEP]\n",
      "torch.Size([1, 29]) tensor([[  101,  1610, 13312,   112,   188,  9579,   118,  1339,  9285,  1110,\n",
      "          1185,  1801,  1111,  1103, 22233,  9717,  2386,  5444,  1119,  1144,\n",
      "         21165,  1114,  5871, 14791,  1116,  2284,  2953,   119,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] carvey's rubber - face routine is no match for the insipid script he has crafted with harris goldberg. [SEP]\n",
      "torch.Size([1, 33]) tensor([[  101,   170,  1277,  1167,  2265,  5179,  1190,  1157,  1211,  2505,\n",
      "          2166,  1273,  6350,   117,  2432,   118,  1900, 22904,  8613,  1183,\n",
      "         15688,  1399,   112,   188,  9279,  8054,  2459,  9304, 10721,  1324,\n",
      "          1707,   119,   102]], device='cuda:0')\n",
      "[CLS] a much more successful translation than its most famous previous film adaptation, writer - director anthony friedman's similarly updated 1970 british production. [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1126, 13157,  1193, 20787, 14175,  1683,  1104,  1103,  1313,\n",
      "          2041,  7893,   119,   102]], device='cuda:0')\n",
      "[CLS] an infinitely wittier version of the home alone formula. [SEP]\n",
      "torch.Size([1, 11]) tensor([[  101,   112,   188, 12759,   117, 21124,   117,  6782,  1105, 24449,\n",
      "           102]], device='cuda:0')\n",
      "[CLS]'s affecting, amusing, sad and reflective [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1104,  1103, 14939,  2130,  9712, 25603,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] of the lightweight female empowerment [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 22405,  1105,  1720,   102]], device='cuda:0')\n",
      "[CLS] ambiguous and nothing [SEP]\n",
      "torch.Size([1, 17]) tensor([[  101,  1194,  3127,  2937,  1201,  1104,   187, 13356,  1811,  3057,\n",
      "          4193,  1105,   170, 15660,  4301,  8337,   102]], device='cuda:0')\n",
      "[CLS] through 300 hundred years of russian cultural identity and a stunning technical achievement [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1110, 1157, 6818, 2463,  102]], device='cuda:0')\n",
      "[CLS] is its essential problem [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  1185, 17400,  1103,  1540,  1104,   185,  5326,  2316,  2293,\n",
      "           112,   188,  1273,   102]], device='cuda:0')\n",
      "[CLS] no denying the power of polanski's film [SEP]\n",
      "torch.Size([1, 48]) tensor([[  101,  1110,  1720,  1133,   170, 14785, 17863,  1766,  5614,  1104,\n",
      "          9304, 13465,  1158, 13497,  1115, 10686,  1164,  1112,  1191,  1152,\n",
      "          1127,  1909,  1171,  1121,  4482,  1959,  3227,   118,   118,   170,\n",
      "           173, 20876,  1183,  3362,  1107,  8057, 26014,  1118,  1157,  1319,\n",
      "          3073,  5208,  3121,  2285,  2191,   118,  8179,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] is nothing but a convenient conveyor belt of brooding personalities that parade about as if they were coming back from stock character camp - - a drowsy drama infatuated by its own pretentious self - examination [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101,  1112,   170,  1685,  1590,  1104,  1632, 11967,   117,  5565,\n",
      "          5864,  1785,  1105, 24500,   102]], device='cuda:0')\n",
      "[CLS] as a young woman of great charm, generosity and diplomacy [SEP]\n",
      "torch.Size([1, 8]) tensor([[ 101, 1674, 2080, 1146, 2785, 1218,  119,  102]], device='cuda:0')\n",
      "[CLS] does hold up pretty well. [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 19758,  4283,   102]], device='cuda:0')\n",
      "[CLS] beautifully shaped [SEP]\n",
      "torch.Size([1, 20]) tensor([[  101,  2004, 25550,   118,   118,  2035,  1104,  1103, 22121,  1116,\n",
      "          1110,   170, 12675,  6730,  1115, 14756, 12362,  1105, 13657,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] episode ii - - attack of the clones is a technological exercise that lacks juice and delight [SEP]\n",
      "torch.Size([1, 3]) tensor([[  101, 12178,   102]], device='cuda:0')\n",
      "[CLS] nightmare [SEP]\n",
      "torch.Size([1, 30]) tensor([[  101,   170,  4618,  9140,  1642,  1110,  1253,   170,  9140,  1642,\n",
      "          1105,   170, 21361,  1988,  9359,  1116,  1104,  1103,  1150,  7641,\n",
      "          2605,  1204,   192,  1186,   183,   112,   189,  1129,  9333,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] a literary detective story is still a detective story and aficionados of the whodunit won't be disappointed [SEP]\n",
      "torch.Size([1, 8]) tensor([[  101,  1103,  1707,  1110,  4228,  5382, 12002,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] the production is suitably elegant [SEP]\n",
      "torch.Size([1, 5]) tensor([[  101, 10133,  1105,  6278,   102]], device='cuda:0')\n",
      "[CLS] consumed and forgotten [SEP]\n",
      "torch.Size([1, 14]) tensor([[  101,  3253,  7385,  2801,  1115,  1231,  2142,  2193,  1114,  5250,\n",
      "         14703, 12090,  2340,   102]], device='cuda:0')\n",
      "[CLS] easily accessible stories that resonate with profundity [SEP]\n",
      "torch.Size([1, 25]) tensor([[  101,  1126,  7291,  3484,  5562,  3613, 14609,  1116,  1105,  7957,\n",
      "         19609,  3384, 12513,  1116,  1104,   170,  2030,  5184,  3703,  2903,\n",
      "          1103,  1958,  8362, 10787,   102]], device='cuda:0')\n",
      "[CLS] anachronistic quick edits and occasional jarring glimpses of a modern theater audience watching the events unfold [SEP]\n",
      "torch.Size([1, 15]) tensor([[  101,  1103,  2209,  1965, 12246,  1106,  1202,   170,  1376, 14979,\n",
      "          1104,  1157,  1319,   119,   102]], device='cuda:0')\n",
      "[CLS] the attention process tends to do a little fleeing of its own. [SEP]\n",
      "torch.Size([1, 13]) tensor([[ 101, 8218, 1366, 1114, 1126, 2168, 2523, 1115, 2140, 1144,  170, 3575,\n",
      "          102]], device='cuda:0')\n",
      "[CLS] presents us with an action movie that actually has a brain [SEP]\n",
      "torch.Size([1, 9]) tensor([[  101,  1263,   118,  1113,   118,  1103,   118, 12202,   102]],\n",
      "       device='cuda:0')\n",
      "[CLS] long - on - the - shelf [SEP]\n",
      "torch.Size([1, 9]) tensor([[ 101, 4928, 1105, 2526,  118, 4240, 4374, 2650,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] plot and paper - thin supporting characters [SEP]\n",
      "torch.Size([1, 45]) tensor([[  101,  9321, 20524,  1114,  1103, 16688,  2578,  1105,  1103,  1845,\n",
      "          3317,   112,   188,  8362,  5480, 10522,  1183,  1440,   117,  1900,\n",
      "          3489,  1200,   188,  1566,  7912,  1116,  1107, 11708,  1643,  9538,\n",
      "          4999, 20866,  1116,  2501,  4899,  1121,  1103,  1273,  1107, 14047,\n",
      "          1297,  1447,  5769,   119,   102]], device='cuda:0')\n",
      "[CLS] seemingly disgusted with the lazy material and the finished product's unshapely look, director fisher stevens inexplicably dips key moments from the film in waking life water colors. [SEP]\n",
      "torch.Size([1, 4]) tensor([[  101, 11516,  1273,   102]], device='cuda:0')\n",
      "[CLS] propaganda film [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  1110,  1157, 15462, 27887,   119,   102]], device='cuda:0')\n",
      "[CLS] is its utter sincerity. [SEP]\n",
      "torch.Size([1, 13]) tensor([[  101,  1175,  1132,  4899,  1104, 20844,  5815,  1785,  1106,  1129,\n",
      "          1125,   119,   102]], device='cuda:0')\n",
      "[CLS] there are moments of hilarity to be had. [SEP]\n",
      "torch.Size([1, 10]) tensor([[ 101,  178, 5242, 1110,  170, 6927, 1104,  170, 3235,  102]],\n",
      "       device='cuda:0')\n",
      "[CLS] ivan is a prince of a fellow [SEP]\n",
      "torch.Size([1, 6]) tensor([[ 101, 1157, 3607, 1171, 9936,  102]], device='cuda:0')\n",
      "[CLS] its critical backlash [SEP]\n",
      "torch.Size([1, 7]) tensor([[  101,  4267,  1116,  1874, 16156,  1895,   102]], device='cuda:0')\n",
      "[CLS] disreputable [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1106,  1322,  1113,   170,  3112,   113,  1191, 15372,   114,\n",
      "          3805,   102]], device='cuda:0')\n",
      "[CLS] to end on a positive ( if tragic ) note [SEP]\n",
      "torch.Size([1, 12]) tensor([[  101,  1198, 11033,  1279,  1154,  8362,  3031, 19221,  9304, 10721,\n",
      "          1324,   102]], device='cuda:0')\n",
      "[CLS] just lapses into unhidden british [SEP]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, train_loader, epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), targets)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# N, T, V = outputs.shape\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# loss = criterion(outputs.view(N * T, V), targets.view(N * T))\u001b[39;00m\n\u001b[0;32m     43\u001b[0m   \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     47\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = train(\n",
    "    model, criterion, optimizer, train_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m prediction_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack((input_ids, prediction_id\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m---> 15\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mones_like(input_ids)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_id \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39msep_token_id:\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m prediction_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack((input_ids, prediction_id\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m---> 15\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mones_like(input_ids)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_id \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39msep_token_id:\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate something\n",
    "prompt = \"it's a\"\n",
    "\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "# prepare inputs + get rid of SEP token at the end\n",
    "input_ids = tokenized_prompt['input_ids'][:, :-1].to(device)\n",
    "mask = tokenized_prompt['attention_mask'][:, :-1].to(device)\n",
    "\n",
    "for _ in range(20):\n",
    "  outputs = model(input_ids, mask)\n",
    "  prediction_id = torch.argmax(outputs[:, -1, :], axis=-1)\n",
    "\n",
    "  input_ids = torch.hstack((input_ids, prediction_id.view(1, 1)))\n",
    "  mask = torch.ones_like(input_ids)\n",
    "\n",
    "  if prediction_id == tokenizer.sep_token_id:\n",
    "    break\n",
    "\n",
    "tokenizer.decode(input_ids[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
