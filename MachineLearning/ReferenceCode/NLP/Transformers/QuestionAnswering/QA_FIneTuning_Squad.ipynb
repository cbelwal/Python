{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SQuAD (Standford Question and Answer Dataset) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"squad\")\n",
    "#raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some value of the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f4190066117f',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'What is in front of the Notre Dame Main Building?',\n",
       " 'answers': {'text': ['a copper statue of Christ'], 'answer_start': [188]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summary:\",raw_datasets)\n",
    "\n",
    "raw_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation DS can have multiple answers\n",
    "raw_datasets[\"validation\"][2][\"answers\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw token ids: {'input_ids': [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decoded tokens: [CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Try with sample data\n",
    "context = raw_datasets[\"train\"][1][\"context\"]\n",
    "question = raw_datasets[\"train\"][1][\"question\"]\n",
    "\n",
    "# Note: Inputs only contain a single row of data\n",
    "inputs = tokenizer(question, context)\n",
    "print(\"Raw token ids:\",inputs)\n",
    "\n",
    "# Decode the token ids\n",
    "print(\"Decoded tokens:\",tokenizer.decode(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked context ids: [[101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 9538, 1110, 1103, 144, 10595, 2430, 117, 170, 14789, 1282, 1104, 8070, 1105, 9284, 119, 1135, 1110, 170, 16498, 1104, 1103, 176, 10595, 2430, 1120, 10111, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 102], [101, 1327, 1110, 1107, 1524, 1104, 1103, 10360, 8022, 4304, 4334, 136, 102, 20500, 117, 1699, 1187, 1103, 6567, 2090, 25153, 1193, 1691, 1106, 2216, 17666, 6397, 3786, 1573, 25422, 13149, 1107, 8109, 119, 1335, 1103, 1322, 1104, 1103, 1514, 2797, 113, 1105, 1107, 170, 2904, 1413, 1115, 8200, 1194, 124, 11739, 1105, 1103, 3487, 17917, 114, 117, 1110, 170, 3014, 117, 2030, 2576, 5921, 1104, 2090, 119, 102]]\n",
      "Decoded and chunked tokens: [CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
      "Decoded and chunked tokens: [CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
      "Decoded and chunked tokens: [CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
      "Decoded and chunked tokens: [CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# More complex tokenizer\n",
    "# Split context into multiple chunks\n",
    "# Split it into multiple samples using overlapping chunks\n",
    "inputs = tokenizer(\n",
    "  question,\n",
    "  context,\n",
    "  max_length=100, # max length of the string\n",
    "  truncation=\"only_second\", # only chunk/truncate second string which is the context\n",
    "  stride=50, # overlap between chunks\n",
    "  # better name for return_overflowing_tokens would be return_overlapping_tokens \n",
    "  return_overflowing_tokens=True, # Set to True, will chunk other tokens beyond the max_length\n",
    "  return_offsets_mapping=True  \n",
    ")\n",
    "\n",
    "# Print the chunks inputs for the 1 data row\n",
    "# each chunk token id will start for 101(for CLS) and end with 102 (for SEP)\n",
    "print(\"Chunked context ids:\",inputs[\"input_ids\"])\n",
    "\n",
    "# Decode the individual token ids\n",
    "# Note the decoded question will be same in all cases\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "  print(\"Decoded and chunked tokens:\",tokenizer.decode(ids))\n",
    "\n",
    "# Format is [CLS] question [SEP] context [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the new keys overflow_to_sample_mapping and offset_mapping\n",
    "\n",
    "overflow_to_sample_mapping: will contain [0, 0, 0, 1, 1, 2, 2] which shows how input data is split into multiple samples\n",
    "\n",
    "[0, 0, 0, 1, 1, 2, 2] it will show how first sample [0] is split into 3 samples, [1] is split into 2 samples and [2] is split into 1, 2 are\n",
    "split into 2 samples\n",
    "\n",
    "offset_mapping: Shows offset/character positions of tokens in the mapping. For example, if the decoded tokens are:\n",
    "\n",
    "[CLS] What is in front of the Notre Dame Main Building?\n",
    "\n",
    "The offset mapping will be like: [(0, 0), (0, 4), (5, 7), (8, 10), ...\n",
    "\n",
    "(0,0) : for CLS\n",
    "(0,4) : For 'What', start from 0 and go till offset 4 as length is 4\n",
    "(5,7) : For 'is', start from 5 and go till offset 7 as length is 2\n",
    "(8,10): For 'in', start from 8 and go till offset 10 as length is 2\n",
    "\n",
    "Note this list restart from (0,0) for a new chunk, but the index still refers to the original string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "inputs['overflow_to_sample_mapping']\n",
    "\n",
    "# Output will be (0,0,0,0), which show that all the 4 chunks belong to the same data row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (0, 13),\n",
       "  (13, 15),\n",
       "  (15, 16),\n",
       "  (17, 20),\n",
       "  (21, 27),\n",
       "  (28, 31),\n",
       "  (32, 33),\n",
       "  (34, 42),\n",
       "  (43, 52),\n",
       "  (52, 53),\n",
       "  (54, 56),\n",
       "  (56, 58),\n",
       "  (59, 62),\n",
       "  (63, 67),\n",
       "  (68, 76),\n",
       "  (76, 77),\n",
       "  (77, 78),\n",
       "  (79, 83),\n",
       "  (84, 88),\n",
       "  (89, 91),\n",
       "  (92, 93),\n",
       "  (94, 100),\n",
       "  (101, 107),\n",
       "  (108, 110),\n",
       "  (111, 114),\n",
       "  (115, 121),\n",
       "  (122, 126),\n",
       "  (126, 127),\n",
       "  (128, 139),\n",
       "  (140, 142),\n",
       "  (143, 148),\n",
       "  (149, 151),\n",
       "  (152, 155),\n",
       "  (156, 160),\n",
       "  (161, 169),\n",
       "  (170, 173),\n",
       "  (174, 180),\n",
       "  (181, 183),\n",
       "  (183, 184),\n",
       "  (185, 187),\n",
       "  (188, 189),\n",
       "  (190, 196),\n",
       "  (197, 203),\n",
       "  (204, 206),\n",
       "  (207, 213),\n",
       "  (214, 218),\n",
       "  (219, 223),\n",
       "  (224, 226),\n",
       "  (226, 229),\n",
       "  (229, 232),\n",
       "  (233, 237),\n",
       "  (238, 241),\n",
       "  (242, 248),\n",
       "  (249, 250),\n",
       "  (250, 251),\n",
       "  (251, 254),\n",
       "  (254, 256),\n",
       "  (257, 259),\n",
       "  (260, 262),\n",
       "  (263, 264),\n",
       "  (264, 265),\n",
       "  (265, 268),\n",
       "  (268, 269),\n",
       "  (269, 270),\n",
       "  (271, 275),\n",
       "  (276, 278),\n",
       "  (279, 282),\n",
       "  (283, 287),\n",
       "  (288, 296),\n",
       "  (297, 299),\n",
       "  (300, 303),\n",
       "  (304, 312),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (174, 180),\n",
       "  (181, 183),\n",
       "  (183, 184),\n",
       "  (185, 187),\n",
       "  (188, 189),\n",
       "  (190, 196),\n",
       "  (197, 203),\n",
       "  (204, 206),\n",
       "  (207, 213),\n",
       "  (214, 218),\n",
       "  (219, 223),\n",
       "  (224, 226),\n",
       "  (226, 229),\n",
       "  (229, 232),\n",
       "  (233, 237),\n",
       "  (238, 241),\n",
       "  (242, 248),\n",
       "  (249, 250),\n",
       "  (250, 251),\n",
       "  (251, 254),\n",
       "  (254, 256),\n",
       "  (257, 259),\n",
       "  (260, 262),\n",
       "  (263, 264),\n",
       "  (264, 265),\n",
       "  (265, 268),\n",
       "  (268, 269),\n",
       "  (269, 270),\n",
       "  (271, 275),\n",
       "  (276, 278),\n",
       "  (279, 282),\n",
       "  (283, 287),\n",
       "  (288, 296),\n",
       "  (297, 299),\n",
       "  (300, 303),\n",
       "  (304, 312),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (374, 377),\n",
       "  (377, 379),\n",
       "  (379, 380),\n",
       "  (381, 382),\n",
       "  (383, 389),\n",
       "  (390, 395),\n",
       "  (396, 398),\n",
       "  (399, 405),\n",
       "  (406, 409),\n",
       "  (410, 420),\n",
       "  (420, 421),\n",
       "  (422, 424),\n",
       "  (425, 427),\n",
       "  (428, 429),\n",
       "  (430, 437),\n",
       "  (438, 440),\n",
       "  (441, 444),\n",
       "  (445, 446),\n",
       "  (446, 449),\n",
       "  (449, 451),\n",
       "  (452, 454),\n",
       "  (455, 458),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 358),\n",
       "  (358, 361),\n",
       "  (361, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 374),\n",
       "  (374, 377),\n",
       "  (377, 379),\n",
       "  (379, 380),\n",
       "  (381, 382),\n",
       "  (383, 389),\n",
       "  (390, 395),\n",
       "  (396, 398),\n",
       "  (399, 405),\n",
       "  (406, 409),\n",
       "  (410, 420),\n",
       "  (420, 421),\n",
       "  (422, 424),\n",
       "  (425, 427),\n",
       "  (428, 429),\n",
       "  (430, 437),\n",
       "  (438, 440),\n",
       "  (441, 444),\n",
       "  (445, 446),\n",
       "  (446, 449),\n",
       "  (449, 451),\n",
       "  (452, 454),\n",
       "  (455, 458),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (528, 531),\n",
       "  (532, 534),\n",
       "  (534, 537),\n",
       "  (537, 541),\n",
       "  (542, 544),\n",
       "  (545, 549),\n",
       "  (549, 550),\n",
       "  (551, 553),\n",
       "  (554, 557),\n",
       "  (558, 561),\n",
       "  (562, 564),\n",
       "  (565, 568),\n",
       "  (569, 573),\n",
       "  (574, 579),\n",
       "  (580, 581),\n",
       "  (581, 584),\n",
       "  (585, 587),\n",
       "  (588, 589),\n",
       "  (590, 596),\n",
       "  (597, 601),\n",
       "  (602, 606),\n",
       "  (607, 615),\n",
       "  (616, 623),\n",
       "  (624, 625),\n",
       "  (626, 633),\n",
       "  (634, 637),\n",
       "  (638, 641),\n",
       "  (642, 646),\n",
       "  (647, 651),\n",
       "  (651, 652),\n",
       "  (652, 653),\n",
       "  (654, 656),\n",
       "  (657, 658),\n",
       "  (659, 665),\n",
       "  (665, 666),\n",
       "  (667, 673),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 7),\n",
       "  (8, 10),\n",
       "  (11, 16),\n",
       "  (17, 19),\n",
       "  (20, 23),\n",
       "  (24, 29),\n",
       "  (30, 34),\n",
       "  (35, 39),\n",
       "  (40, 48),\n",
       "  (48, 49),\n",
       "  (0, 0),\n",
       "  (458, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 500),\n",
       "  (500, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 525),\n",
       "  (525, 528),\n",
       "  (528, 531),\n",
       "  (532, 534),\n",
       "  (534, 537),\n",
       "  (537, 541),\n",
       "  (542, 544),\n",
       "  (545, 549),\n",
       "  (549, 550),\n",
       "  (551, 553),\n",
       "  (554, 557),\n",
       "  (558, 561),\n",
       "  (562, 564),\n",
       "  (565, 568),\n",
       "  (569, 573),\n",
       "  (574, 579),\n",
       "  (580, 581),\n",
       "  (581, 584),\n",
       "  (585, 587),\n",
       "  (588, 589),\n",
       "  (590, 596),\n",
       "  (597, 601),\n",
       "  (602, 606),\n",
       "  (607, 615),\n",
       "  (616, 623),\n",
       "  (624, 625),\n",
       "  (626, 633),\n",
       "  (634, 637),\n",
       "  (638, 641),\n",
       "  (642, 646),\n",
       "  (647, 651),\n",
       "  (651, 652),\n",
       "  (652, 653),\n",
       "  (654, 656),\n",
       "  (657, 658),\n",
       "  (659, 665),\n",
       "  (665, 666),\n",
       "  (667, 673),\n",
       "  (674, 679),\n",
       "  (680, 686),\n",
       "  (687, 689),\n",
       "  (690, 694),\n",
       "  (694, 695),\n",
       "  (0, 0)]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each SEP token will show up as (0,0) in this\n",
    "inputs['offset_mapping'] # Shows index of each token in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " None,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " None]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For out example, there are 4 inputs chunks, and each chunk has question and chunked context\n",
    "# the sequence id will be 0 for question and 1 for context, for each of the chunk ids passed to it \n",
    "# this is similar to token type ids\n",
    "\n",
    "inputs.sequence_ids(0)  # Shows the sequence id of each token for chunk 0\n",
    "\n",
    "# NOTE: inputs.sequence_ids(4) will throw an error as there are only 4 chunks\n",
    "# SEP and CLS tokens will be shown as none "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = raw_datasets[\"train\"][1][\"answers\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 98)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find index in sequence_id where context starts\n",
    "# Remember that the sequence_id is 0 for question and 1 for context\n",
    "\n",
    "sequence_ids = inputs.sequence_ids(0)\n",
    "\n",
    "#x:y:z in Python means to start at x, end at y, and step by z \n",
    "# find where sequence_id changes from 0 to 1\n",
    "ctx_start = sequence_ids.index(1) # .index() will return the first index where the value is 1\n",
    "# sequence_ids[::-1].index(1) will returns from the other side of the list where the value is 1\n",
    "idx = sequence_ids[::-1].index(1) # will return 1 => second index from right where 1 starts \n",
    "ctx_end= len(sequence_ids) - idx - 1 # find the last index where the value is 1\n",
    "# Example: sequence_ids = [0,0,1,1,1,1,None]\n",
    "# ctx_start = 2, ctx_end = 7 - 1 - 1 = 5\n",
    "ctx_start, ctx_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: {'text': ['a copper statue of Christ'], 'answer_start': [188]}\n",
      "offset: [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "# check whether or not the answer is fully contained within the context\n",
    "# if not, target is (start, end) = (0, 0)\n",
    "print(\"answer:\",answer)\n",
    "\n",
    "ans_start_char = answer['answer_start'][0] # location in first index, will return 188 for the sample\n",
    "ans_end_char = ans_start_char + len(answer['text'][0])\n",
    "\n",
    "offset = inputs['offset_mapping'][0] #[0] give first question and context chunk\n",
    "print(\"offset:\",offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_idx, end_idx: (53, 57)\n"
     ]
    }
   ],
   "source": [
    "# The answer is provided in terms of character positions in the context\n",
    "# However for neurl network, we need to provide the answer in terms of token positions\n",
    "# This function will find the token positions of the answer in the context\n",
    "def find_answer_token_idx(\n",
    "    ctx_start,\n",
    "    ctx_end,\n",
    "    ans_start_char,\n",
    "    ans_end_char,\n",
    "    offset):\n",
    "  \n",
    "  start_idx = 0\n",
    "  end_idx = 0\n",
    "\n",
    "  if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
    "    pass\n",
    "    # print(\"target is (0, 0)\")\n",
    "    # nothing else to do\n",
    "  else:\n",
    "    # find the start and end TOKEN positions\n",
    "\n",
    "    # the 'trick' is knowing what is in units of tokens and what is in\n",
    "    # units of characters\n",
    "\n",
    "    # recall: the offset_mapping contains the character positions of each token\n",
    "\n",
    "    i = ctx_start\n",
    "    for start_end_char in offset[ctx_start:]:\n",
    "      start, end = start_end_char\n",
    "      if start == ans_start_char:\n",
    "        start_idx = i\n",
    "        # don't break yet\n",
    "      \n",
    "      if end == ans_end_char:\n",
    "        end_idx = i\n",
    "        break\n",
    "\n",
    "      i += 1\n",
    "  return start_idx, end_idx\n",
    "\n",
    "# Token positions where the answer starts and ends\n",
    "start_idx, end_idx = find_answer_token_idx(ctx_start, ctx_end, ans_start_char, ans_end_char, offset)\n",
    "\n",
    "print (f\"start_idx, end_idx: {start_idx, end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ids for answer [170, 7335, 5921, 1104, 4028]\n",
      "Decoded Values: a copper statue of Christ\n"
     ]
    }
   ],
   "source": [
    "# Verify the values of the answers based on the start_idx and end_idx\n",
    "# Check the Token ids\n",
    "input_ids = inputs['input_ids'][0]\n",
    "print(\"Token ids for answer\",input_ids[start_idx : end_idx + 1])\n",
    "\n",
    "# Decoded values of the tokens\n",
    "print(\"Decoded Values:\",tokenizer.decode(input_ids[start_idx : end_idx + 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the process of tokenizing the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenize function for the entire batch which will be called from the map function\n",
    "\n",
    "# Use these values as Google used 384 for SQuAD\n",
    "max_length = 384\n",
    "stride =  128\n",
    "\n",
    "# This function is used only for the train data\n",
    "def tokenize_fn_train(batch):\n",
    "  # some questions have leading and/or trailing whitespace\n",
    "  questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "  # tokenize the data (with padding this time)\n",
    "  # since most contexts are long, we won't bother to pad per-minibatch\n",
    "  inputs = tokenizer(\n",
    "    questions,\n",
    "    batch[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    stride=stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "  )\n",
    "\n",
    "  # we don't need these later so remove them from the dict\n",
    "  # offset mapping will have the question first followed by the chunked context \n",
    "  offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\") # Shows which chunk belongs to which sample\n",
    "  # e.g. orig_sample_idxs = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]\n",
    "  # => Chunk 0-3 belongs to sample 0, Chunk 4-7 belongs to sample 1, Chunk 8-11 belongs to sample 2\n",
    "  answers = batch['answers']\n",
    "  start_idxs, end_idxs = [], []\n",
    "\n",
    "  # Put the start and end position of the answers\n",
    "  # in the end positions, we will use the function defined previously\n",
    "  # offset_mapping = [[(0,1),(2,5)...],[(0,6),(7,12)...],...]\n",
    "  for i, offset in enumerate(offset_mapping): # i, offset =   0, [(0,1),(2,5)...] \n",
    "    sample_idx = orig_sample_idxs[i] # Sample index will be sample for multiple chunks of same sample\n",
    "    \n",
    "    # Searching for the answer in the specific context\n",
    "    answer = answers[sample_idx]\n",
    "    ans_start_char = answer['answer_start'][0]\n",
    "    ans_end_char = ans_start_char + len(answer['text'][0])\n",
    "\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # find start + end of context (first 1 and last 1)\n",
    "    # We will find if the answer is in this chunked context or not\n",
    "    ctx_start = sequence_ids.index(1)\n",
    "    ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) - 1\n",
    "\n",
    "    start_idx, end_idx = find_answer_token_idx(\n",
    "      ctx_start,\n",
    "      ctx_end,\n",
    "      ans_start_char,\n",
    "      ans_end_char,\n",
    "      offset)\n",
    "\n",
    "    # Note that due to stride the answer can appear in multiple context \n",
    "    # windows\n",
    "    start_idxs.append(start_idx) # if start_idx = end_idx = 0, then answer is not in the context\n",
    "    end_idxs.append(end_idx)\n",
    "  \n",
    "  # Add new fields in the input.\n",
    "  inputs[\"start_positions\"] = start_idxs\n",
    "  inputs[\"end_positions\"] = end_idxs\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [00:29<00:00, 3016.50 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m raw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m      4\u001b[0m   tokenize_fn_train,\n\u001b[0;32m      5\u001b[0m   batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m   remove_columns\u001b[38;5;241m=\u001b[39mraw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names, \u001b[38;5;66;03m# will remove the column_names \u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# remove_columns will remove the columns from the dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# See the difference in the length of the raw dataset and the tokenized dataset\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mlen\u001b[39m(raw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(train_dataset)\n",
      "Cell \u001b[1;32mIn[89], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m raw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m      4\u001b[0m   tokenize_fn_train,\n\u001b[0;32m      5\u001b[0m   batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m   remove_columns\u001b[38;5;241m=\u001b[39mraw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names, \u001b[38;5;66;03m# will remove the column_names \u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# remove_columns will remove the columns from the dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# See the difference in the length of the raw dataset and the tokenized dataset\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mlen\u001b[39m(raw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(train_dataset)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare the train dataset\n",
    "# Use the mapping functions to tokenize the data\n",
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "  tokenize_fn_train,\n",
    "  batched=True,\n",
    "  # Will remove all columns present in original data in the new dataset\n",
    "  # This will insure that none of the original columns are present in the new dataset\n",
    "  # as they are not used \n",
    "  remove_columns=raw_datasets[\"train\"].column_names, \n",
    ")\n",
    "\n",
    "# remove_columns will remove the columns from the dataset\n",
    "# See the difference in the length of the raw dataset and the tokenized dataset\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do data prep for validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  'answer_start': [177, 177, 177]}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one Sample\n",
    "raw_datasets[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the validation set differently\n",
    "# we won't need the targets since we will just compare with the original answer\n",
    "# also: overwrite offset_mapping with Nones in place of question\n",
    "def tokenize_fn_validation(batch):\n",
    "  # some questions have leading and/or trailing whitespace, strip them\n",
    "  questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "  # tokenize the data (with padding this time)\n",
    "  # since most contexts are long, we won't bother to pad per-minibatch\n",
    "  inputs = tokenizer(\n",
    "    questions,\n",
    "    batch[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    stride=stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",\n",
    "  )\n",
    "\n",
    "  # we don't need these later so remove them\n",
    "  # keep the offset mapping as it will be used to find the answer\n",
    "  orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "  sample_ids = []\n",
    "\n",
    "  # rewrite offset mapping by replacing question tuples with None\n",
    "  # this will be helpful later on when we compute metrics\n",
    "  for i in range(len(inputs[\"input_ids\"])):\n",
    "    sample_idx = orig_sample_idxs[i]\n",
    "    sample_ids.append(batch['id'][sample_idx])\n",
    "\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    offset = inputs[\"offset_mapping\"][i]\n",
    "    # Change any value that does not belong to the context to None\n",
    "    # Remember that the sequence_id is 0 for question and 1 for context\n",
    "    inputs[\"offset_mapping\"][i] = [\n",
    "      x if sequence_ids[j] == 1 else None for j, x in enumerate(offset)]\n",
    "    \n",
    "  inputs['sample_id'] = sample_ids\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10570/10570 [00:04<00:00, 2219.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10570, 10822)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the validation dataset using map function defined earlier\n",
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "  tokenize_fn_validation,\n",
    "  batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "# The length will differ as chunking will create additional samples\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build code for the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.53k/4.53k [00:00<00:00, 9.92MB/s]\n",
      "Downloading extra modules: 100%|██████████| 3.32k/3.32k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# ----------- This is not used anymore\n",
    "# from datasets import load_metric\n",
    "# metric = load_metric(\"squad\")\n",
    "#------------------------\n",
    "#pip install evaluate\n",
    "import evaluate\n",
    "\n",
    "# Most standards datasets for NLP tasks have associated metrics for them\n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a sample structures of predicted and true answers, and how they are passed to the compute function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 66.66666666666667, 'f1': 83.33333333333333}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers = [\n",
    "  {'id': '1', 'prediction_text': 'Albert Einstein'},\n",
    "  {'id': '2', 'prediction_text': 'physicist'},\n",
    "  {'id': '3', 'prediction_text': 'general relativity'},\n",
    "]\n",
    "true_answers = [\n",
    "  {'id': '1', 'answers': {'text': ['Albert Einstein'], 'answer_start': [100]}},\n",
    "  {'id': '2', 'answers': {'text': ['physicist'], 'answer_start': [100]}},\n",
    "  {'id': '3', 'answers': {'text': ['special relativity'], 'answer_start': [100]}},\n",
    "]\n",
    "\n",
    "# id and answer_start seem superfluous but you'll get an error if not included\n",
    "# metrics.compute will give accuracy and F1 score\n",
    "metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a smaller validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitanya Belwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Chaitanya Belwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Chaitanya Belwal\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1700.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# next problem: how to go from logits to prediction text?\n",
    "small_validation_dataset = raw_datasets[\"validation\"].select(range(100)) # select 1 to 100\n",
    "\n",
    "# Let's work on an already-trained question-answering model\n",
    "# Model name will be used in both AutoTokenizer and AutoModelForQuestionAnswering\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "# temporarily assign tokenizer2 to tokenizer since it's used as a global\n",
    "# in tokenize_fn_validation. The original tokenizer is declared earlier in the code\n",
    "old_tokenizer = tokenizer\n",
    "tokenizer = tokenizer2\n",
    "\n",
    "small_validation_processed = small_validation_dataset.map(\n",
    "    tokenize_fn_validation,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "\n",
    "# change it back\n",
    "tokenizer = old_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the definition of the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model prepped for training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
